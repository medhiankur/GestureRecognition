{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gesture Recognition\n",
        "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
      ],
      "metadata": {
        "id": "gXoqzEardcQF"
      },
      "id": "gXoqzEardcQF"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d48279ac",
      "metadata": {
        "id": "d48279ac"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "#from scipy.misc import imread, imresize\n",
        "import cv2\n",
        "import imageio\n",
        "import datetime\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ],
      "metadata": {
        "id": "Wq6kSqA8dimJ"
      },
      "id": "Wq6kSqA8dimJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "962f2c42",
      "metadata": {
        "id": "962f2c42"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
      ],
      "metadata": {
        "id": "sSCXF0Ordp6D"
      },
      "id": "sSCXF0Ordp6D"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f7EZIuc-wXE",
        "outputId": "4989afe4-77b8-4af9-feda-4676eae5cf5c"
      },
      "id": "4f7EZIuc-wXE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2c6656b",
      "metadata": {
        "id": "d2c6656b"
      },
      "outputs": [],
      "source": [
        "train_doc = np.random.permutation(open('/content/gdrive/MyDrive/Upgrad/RNN/Project_data/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/gdrive/MyDrive/Upgrad/RNN/Project_data/Project_data/val.csv').readlines())\n",
        "batch_size = 50\n",
        "#experiment with the batch size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
      ],
      "metadata": {
        "id": "qa0Xaac9dxvK"
      },
      "id": "qa0Xaac9dxvK"
    },
    {
      "cell_type": "code",
      "source": [
        "x = 30 # # x is the number of images\n",
        "y = 120 # width of the image\n",
        "z = 120 # height of the image"
      ],
      "metadata": {
        "id": "lLfyjbYjEgNc"
      },
      "id": "lLfyjbYjEgNc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e092367",
      "metadata": {
        "id": "1e092367"
      },
      "outputs": [],
      "source": [
        "def generator(source_path, folder_list, batch_size):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    img_idx = [x for x in range(0,x)] #create a list of image numbers you want to use for a particular video\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    temp = cv2.resize(image,(120,120))\n",
        "                    temp = temp/127.5-1 #Normalize data\n",
        "\n",
        "                    batch_data[folder,idx,:,:,0] = (temp[:,:,0]) #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] = (temp[:,:,1]) #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] = (temp[:,:,2]) #normalise and feed in the image\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "\n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "\n",
        "        if (len(folder_list) != batch_size*num_batches):\n",
        "            print(\"Batch: \",num_batches+1,\"Index:\", batch_size)\n",
        "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
        "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "                    temp = cv2.resize(image,(120,120))\n",
        "                    temp = temp/127.5-1 #Normalize data\n",
        "\n",
        "                    batch_data[folder,idx,:,:,0] = (temp[:,:,0])\n",
        "                    batch_data[folder,idx,:,:,1] = (temp[:,:,1])\n",
        "                    batch_data[folder,idx,:,:,2] = (temp[:,:,2])\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
      ],
      "metadata": {
        "id": "QUMyHrwxd91J"
      },
      "id": "QUMyHrwxd91J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91bb15ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91bb15ac",
        "outputId": "c7febc39-8c70-48d1-b67f-a8724342623b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 30\n"
          ]
        }
      ],
      "source": [
        "\n",
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/content/gdrive/MyDrive/Upgrad/RNN/Project_data/Project_data/train'\n",
        "val_path = '/content/gdrive/MyDrive/Upgrad/RNN/Project_data/Project_data/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "num_epochs = 30\n",
        "print ('# epochs =', num_epochs)\n",
        "# choose the number of epochs\n",
        "#generator(train_path, train_doc, batch_size)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
      ],
      "metadata": {
        "id": "X3EShIWCeDrZ"
      },
      "id": "X3EShIWCeDrZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2195f9af",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "2195f9af"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
        "from keras.layers import Conv3D, MaxPooling3D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_al1 = Sequential()\n",
        "\n",
        "model_al1.add(Conv3D(8, #number of filters\n",
        "                 kernel_size=(3,3,3),\n",
        "                 input_shape=(30, 120, 120, 3),\n",
        "                 padding='same'))\n",
        "model_al1.add(BatchNormalization())\n",
        "model_al1.add(Activation('relu'))\n",
        "\n",
        "model_al1.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "\n",
        "model_al1.add(Conv3D(16, #Number of filters,\n",
        "                 kernel_size=(3,3,3),\n",
        "                 padding='same'))\n",
        "model_al1.add(BatchNormalization())\n",
        "model_al1.add(Activation('relu'))\n",
        "\n",
        "model_al1.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "\n",
        "model_al1.add(Conv3D(32, #Number of filters\n",
        "                 kernel_size=(3,3,3),\n",
        "                 padding='same'))\n",
        "model_al1.add(BatchNormalization())\n",
        "model_al1.add(Activation('relu'))\n",
        "\n",
        "model_al1.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "\n",
        "model_al1.add(Conv3D(64, #Number pf filters\n",
        "                 kernel_size=(3,3,3),\n",
        "                 padding='same'))\n",
        "model_al1.add(BatchNormalization())\n",
        "model_al1.add(Activation('relu'))\n",
        "\n",
        "model_al1.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "\n",
        "#Flatten Layers\n",
        "model_al1.add(Flatten())\n",
        "\n",
        "model_al1.add(Dense(1000, activation='relu'))\n",
        "model_al1.add(Dropout(0.5))\n",
        "\n",
        "model_al1.add(Dense(500, activation='relu'))\n",
        "model_al1.add(Dropout(0.5))\n",
        "\n",
        "#softmax layer\n",
        "model_al1.add(Dense(5, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "hfLYRYw1FRez"
      },
      "id": "hfLYRYw1FRez",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
      ],
      "metadata": {
        "id": "Ya43Fp5ieLp0"
      },
      "id": "Ya43Fp5ieLp0"
    },
    {
      "cell_type": "code",
      "source": [
        "optimiser = optimizers.Adam(lr=0.001) #write your optimizer\n",
        "model_al1.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model_al1.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V9n7JrxFW4N",
        "outputId": "a2b1ea13-89d2-4be9-f7e9-e2127d145082"
      },
      "id": "4V9n7JrxFW4N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_4 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 30, 120, 120, 8)   32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 30, 120, 120, 8)   0         \n",
            "                                                                 \n",
            " max_pooling3d_4 (MaxPoolin  (None, 15, 60, 60, 8)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " conv3d_5 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 15, 60, 60, 16)    64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 15, 60, 60, 16)    0         \n",
            "                                                                 \n",
            " max_pooling3d_5 (MaxPoolin  (None, 7, 30, 30, 16)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " conv3d_6 (Conv3D)           (None, 7, 30, 30, 32)     13856     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 7, 30, 30, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 7, 30, 30, 32)     0         \n",
            "                                                                 \n",
            " max_pooling3d_6 (MaxPoolin  (None, 3, 15, 15, 32)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " conv3d_7 (Conv3D)           (None, 3, 15, 15, 64)     55360     \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 3, 15, 15, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 3, 15, 15, 64)     0         \n",
            "                                                                 \n",
            " max_pooling3d_7 (MaxPoolin  (None, 1, 7, 7, 64)       0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1000)              3137000   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 500)               500500    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 2505      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3713829 (14.17 MB)\n",
            "Trainable params: 3713589 (14.17 MB)\n",
            "Non-trainable params: 240 (960.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us create the train_generator and the val_generator which will be used in .fit_generator."
      ],
      "metadata": {
        "id": "UG8L7ehdeT0x"
      },
      "id": "UG8L7ehdeT0x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed1e935f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed1e935f",
        "outputId": "d3ed5cb1-0081-4b78-d464-991deefe5b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training generator done\n",
            "validation generator done\n"
          ]
        }
      ],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "print(\"training generator done\")\n",
        "val_generator = generator(val_path, val_doc, batch_size)\n",
        "print(\"validation generator done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "566caa9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "566caa9c",
        "outputId": "c64352ba-9299-4aee-a958-0073dbc7ae45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
        "# write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb10c402",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb10c402",
        "outputId": "c668f40b-5ae3-4783-be67-0df1655105f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n",
        "print(steps_per_epoch)\n",
        "print(validation_steps)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
      ],
      "metadata": {
        "id": "VlOf4eZOed9b"
      },
      "id": "VlOf4eZOed9b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8766d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d8766d5",
        "outputId": "e0145a4f-cde8-4c40-9e16-b959bfa8317a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-2dbeb5e89a4d>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model_al1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
            "<ipython-input-6-502af651a6fd>:13: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/gdrive/MyDrive/Upgrad/RNN/Project_data/Project_data/train ; batch size = 50\n",
            "Epoch 1/30\n",
            "11/14 [======================>.......] - ETA: 2:55 - loss: 4.0411 - categorical_accuracy: 0.2364Batch:  14 Index: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-502af651a6fd>:38: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - ETA: 0s - loss: 3.6238 - categorical_accuracy: 0.2519 Source path =  /content/gdrive/MyDrive/Upgrad/RNN/Project_data/Project_data/val ; batch size = 50\n",
            "\n",
            "Epoch 1: saving model to model_init_2023-12-0412_48_39.221333/model-00001-3.62377-0.25189-1.54456-0.23000.h5\n",
            "14/14 [==============================] - 879s 62s/step - loss: 3.6238 - categorical_accuracy: 0.2519 - val_loss: 1.5446 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 1.5499 - categorical_accuracy: 0.3516 \n",
            "Epoch 2: saving model to model_init_2023-12-0412_48_39.221333/model-00002-1.54987-0.35165-1.43839-0.34000.h5\n",
            "14/14 [==============================] - 280s 20s/step - loss: 1.5499 - categorical_accuracy: 0.3516 - val_loss: 1.4384 - val_categorical_accuracy: 0.3400 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 1.4213 - categorical_accuracy: 0.4066 \n",
            "Epoch 3: saving model to model_init_2023-12-0412_48_39.221333/model-00003-1.42134-0.40659-1.39842-0.44000.h5\n",
            "14/14 [==============================] - 300s 22s/step - loss: 1.4213 - categorical_accuracy: 0.4066 - val_loss: 1.3984 - val_categorical_accuracy: 0.4400 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 1.2955 - categorical_accuracy: 0.4176 \n",
            "Epoch 4: saving model to model_init_2023-12-0412_48_39.221333/model-00004-1.29550-0.41758-1.41653-0.40000.h5\n",
            "14/14 [==============================] - 295s 21s/step - loss: 1.2955 - categorical_accuracy: 0.4176 - val_loss: 1.4165 - val_categorical_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 1.2108 - categorical_accuracy: 0.4670 \n",
            "Epoch 5: saving model to model_init_2023-12-0412_48_39.221333/model-00005-1.21077-0.46703-1.73968-0.26000.h5\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "14/14 [==============================] - 297s 22s/step - loss: 1.2108 - categorical_accuracy: 0.4670 - val_loss: 1.7397 - val_categorical_accuracy: 0.2600 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 1.0851 - categorical_accuracy: 0.5440 \n",
            "Epoch 6: saving model to model_init_2023-12-0412_48_39.221333/model-00006-1.08513-0.54396-1.64870-0.26000.h5\n",
            "14/14 [==============================] - 280s 20s/step - loss: 1.0851 - categorical_accuracy: 0.5440 - val_loss: 1.6487 - val_categorical_accuracy: 0.2600 - lr: 5.0000e-04\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 1.0590 - categorical_accuracy: 0.5659 \n",
            "Epoch 7: saving model to model_init_2023-12-0412_48_39.221333/model-00007-1.05895-0.56593-1.59080-0.28000.h5\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "14/14 [==============================] - 299s 22s/step - loss: 1.0590 - categorical_accuracy: 0.5659 - val_loss: 1.5908 - val_categorical_accuracy: 0.2800 - lr: 5.0000e-04\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 1.0796 - categorical_accuracy: 0.5165 \n",
            "Epoch 8: saving model to model_init_2023-12-0412_48_39.221333/model-00008-1.07959-0.51648-1.83190-0.28000.h5\n",
            "14/14 [==============================] - 294s 21s/step - loss: 1.0796 - categorical_accuracy: 0.5165 - val_loss: 1.8319 - val_categorical_accuracy: 0.2800 - lr: 2.5000e-04\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.8780 - categorical_accuracy: 0.6154 \n",
            "Epoch 9: saving model to model_init_2023-12-0412_48_39.221333/model-00009-0.87795-0.61538-2.06128-0.29000.h5\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "14/14 [==============================] - 291s 21s/step - loss: 0.8780 - categorical_accuracy: 0.6154 - val_loss: 2.0613 - val_categorical_accuracy: 0.2900 - lr: 2.5000e-04\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.9918 - categorical_accuracy: 0.6154 \n",
            "Epoch 10: saving model to model_init_2023-12-0412_48_39.221333/model-00010-0.99184-0.61538-1.98661-0.28000.h5\n",
            "14/14 [==============================] - 296s 22s/step - loss: 0.9918 - categorical_accuracy: 0.6154 - val_loss: 1.9866 - val_categorical_accuracy: 0.2800 - lr: 1.2500e-04\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7849 - categorical_accuracy: 0.6758 \n",
            "Epoch 11: saving model to model_init_2023-12-0412_48_39.221333/model-00011-0.78487-0.67582-2.11142-0.29000.h5\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "14/14 [==============================] - 289s 21s/step - loss: 0.7849 - categorical_accuracy: 0.6758 - val_loss: 2.1114 - val_categorical_accuracy: 0.2900 - lr: 1.2500e-04\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.8375 - categorical_accuracy: 0.6813 \n",
            "Epoch 12: saving model to model_init_2023-12-0412_48_39.221333/model-00012-0.83748-0.68132-1.91133-0.29000.h5\n",
            "14/14 [==============================] - 295s 21s/step - loss: 0.8375 - categorical_accuracy: 0.6813 - val_loss: 1.9113 - val_categorical_accuracy: 0.2900 - lr: 6.2500e-05\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7707 - categorical_accuracy: 0.7253 \n",
            "Epoch 13: saving model to model_init_2023-12-0412_48_39.221333/model-00013-0.77074-0.72527-1.75892-0.29000.h5\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "14/14 [==============================] - 298s 22s/step - loss: 0.7707 - categorical_accuracy: 0.7253 - val_loss: 1.7589 - val_categorical_accuracy: 0.2900 - lr: 6.2500e-05\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.9055 - categorical_accuracy: 0.6429 \n",
            "Epoch 14: saving model to model_init_2023-12-0412_48_39.221333/model-00014-0.90549-0.64286-1.78863-0.28000.h5\n",
            "14/14 [==============================] - 285s 21s/step - loss: 0.9055 - categorical_accuracy: 0.6429 - val_loss: 1.7886 - val_categorical_accuracy: 0.2800 - lr: 3.1250e-05\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7317 - categorical_accuracy: 0.7363 \n",
            "Epoch 15: saving model to model_init_2023-12-0412_48_39.221333/model-00015-0.73171-0.73626-1.80046-0.29000.h5\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "14/14 [==============================] - 295s 21s/step - loss: 0.7317 - categorical_accuracy: 0.7363 - val_loss: 1.8005 - val_categorical_accuracy: 0.2900 - lr: 3.1250e-05\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.8067 - categorical_accuracy: 0.6538 \n",
            "Epoch 16: saving model to model_init_2023-12-0412_48_39.221333/model-00016-0.80673-0.65385-1.72194-0.32000.h5\n",
            "14/14 [==============================] - 295s 21s/step - loss: 0.8067 - categorical_accuracy: 0.6538 - val_loss: 1.7219 - val_categorical_accuracy: 0.3200 - lr: 1.5625e-05\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.8046 - categorical_accuracy: 0.6593 \n",
            "Epoch 17: saving model to model_init_2023-12-0412_48_39.221333/model-00017-0.80463-0.65934-1.61225-0.34000.h5\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "14/14 [==============================] - 288s 21s/step - loss: 0.8046 - categorical_accuracy: 0.6593 - val_loss: 1.6123 - val_categorical_accuracy: 0.3400 - lr: 1.5625e-05\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.6521 - categorical_accuracy: 0.7418 \n",
            "Epoch 18: saving model to model_init_2023-12-0412_48_39.221333/model-00018-0.65208-0.74176-1.50408-0.37000.h5\n",
            "14/14 [==============================] - 296s 22s/step - loss: 0.6521 - categorical_accuracy: 0.7418 - val_loss: 1.5041 - val_categorical_accuracy: 0.3700 - lr: 7.8125e-06\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.9174 - categorical_accuracy: 0.6538 \n",
            "Epoch 19: saving model to model_init_2023-12-0412_48_39.221333/model-00019-0.91740-0.65385-1.41146-0.41000.h5\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "14/14 [==============================] - 292s 21s/step - loss: 0.9174 - categorical_accuracy: 0.6538 - val_loss: 1.4115 - val_categorical_accuracy: 0.4100 - lr: 7.8125e-06\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7642 - categorical_accuracy: 0.7308 \n",
            "Epoch 20: saving model to model_init_2023-12-0412_48_39.221333/model-00020-0.76422-0.73077-1.32829-0.44000.h5\n",
            "14/14 [==============================] - 295s 22s/step - loss: 0.7642 - categorical_accuracy: 0.7308 - val_loss: 1.3283 - val_categorical_accuracy: 0.4400 - lr: 3.9063e-06\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7921 - categorical_accuracy: 0.7143 \n",
            "Epoch 21: saving model to model_init_2023-12-0412_48_39.221333/model-00021-0.79206-0.71429-1.24873-0.47000.h5\n",
            "14/14 [==============================] - 295s 22s/step - loss: 0.7921 - categorical_accuracy: 0.7143 - val_loss: 1.2487 - val_categorical_accuracy: 0.4700 - lr: 3.9063e-06\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7736 - categorical_accuracy: 0.6978 \n",
            "Epoch 22: saving model to model_init_2023-12-0412_48_39.221333/model-00022-0.77363-0.69780-1.18327-0.48000.h5\n",
            "14/14 [==============================] - 296s 22s/step - loss: 0.7736 - categorical_accuracy: 0.6978 - val_loss: 1.1833 - val_categorical_accuracy: 0.4800 - lr: 3.9063e-06\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7130 - categorical_accuracy: 0.7692 \n",
            "Epoch 23: saving model to model_init_2023-12-0412_48_39.221333/model-00023-0.71297-0.76923-1.13015-0.52000.h5\n",
            "14/14 [==============================] - 292s 21s/step - loss: 0.7130 - categorical_accuracy: 0.7692 - val_loss: 1.1302 - val_categorical_accuracy: 0.5200 - lr: 3.9063e-06\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7695 - categorical_accuracy: 0.7143 \n",
            "Epoch 24: saving model to model_init_2023-12-0412_48_39.221333/model-00024-0.76946-0.71429-1.07781-0.55000.h5\n",
            "14/14 [==============================] - 296s 21s/step - loss: 0.7695 - categorical_accuracy: 0.7143 - val_loss: 1.0778 - val_categorical_accuracy: 0.5500 - lr: 3.9063e-06\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7448 - categorical_accuracy: 0.6923 \n",
            "Epoch 25: saving model to model_init_2023-12-0412_48_39.221333/model-00025-0.74478-0.69231-1.03055-0.58000.h5\n",
            "14/14 [==============================] - 297s 22s/step - loss: 0.7448 - categorical_accuracy: 0.6923 - val_loss: 1.0305 - val_categorical_accuracy: 0.5800 - lr: 3.9063e-06\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7675 - categorical_accuracy: 0.6868 \n",
            "Epoch 26: saving model to model_init_2023-12-0412_48_39.221333/model-00026-0.76746-0.68681-0.99222-0.59000.h5\n",
            "14/14 [==============================] - 304s 22s/step - loss: 0.7675 - categorical_accuracy: 0.6868 - val_loss: 0.9922 - val_categorical_accuracy: 0.5900 - lr: 3.9063e-06\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.8191 - categorical_accuracy: 0.6813 \n",
            "Epoch 27: saving model to model_init_2023-12-0412_48_39.221333/model-00027-0.81913-0.68132-0.96685-0.61000.h5\n",
            "14/14 [==============================] - 295s 21s/step - loss: 0.8191 - categorical_accuracy: 0.6813 - val_loss: 0.9668 - val_categorical_accuracy: 0.6100 - lr: 3.9063e-06\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7179 - categorical_accuracy: 0.7198 \n",
            "Epoch 28: saving model to model_init_2023-12-0412_48_39.221333/model-00028-0.71791-0.71978-0.94091-0.64000.h5\n",
            "14/14 [==============================] - 294s 21s/step - loss: 0.7179 - categorical_accuracy: 0.7198 - val_loss: 0.9409 - val_categorical_accuracy: 0.6400 - lr: 3.9063e-06\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7941 - categorical_accuracy: 0.6868 \n",
            "Epoch 29: saving model to model_init_2023-12-0412_48_39.221333/model-00029-0.79407-0.68681-0.92159-0.64000.h5\n",
            "14/14 [==============================] - 295s 21s/step - loss: 0.7941 - categorical_accuracy: 0.6868 - val_loss: 0.9216 - val_categorical_accuracy: 0.6400 - lr: 3.9063e-06\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.8052 - categorical_accuracy: 0.6868 \n",
            "Epoch 30: saving model to model_init_2023-12-0412_48_39.221333/model-00030-0.80517-0.68681-0.90369-0.66000.h5\n",
            "14/14 [==============================] - 295s 22s/step - loss: 0.8052 - categorical_accuracy: 0.6868 - val_loss: 0.9037 - val_categorical_accuracy: 0.6600 - lr: 3.9063e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7db876b11990>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model_al1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: 2D Conv + RNN (Transfer Learning using MobileNet)"
      ],
      "metadata": {
        "id": "ItbawMDAe4tK"
      },
      "id": "ItbawMDAe4tK"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_epochs = 25\n",
        "x = 30 # # x is the number of images\n",
        "y = 120 # width of the image\n",
        "z = 120 # height of the image\n",
        "classes = 5 #5 gestures\n",
        "channel = 3 #RGB"
      ],
      "metadata": {
        "id": "1C7Qck1Le6uM"
      },
      "id": "1C7Qck1Le6uM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import mobilenet\n",
        "pretrained_mobilenet = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import LSTM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0Zrwtz9fGDF",
        "outputId": "aa3c2563-5d46-4750-fdcb-ea69e1bc205f"
      },
      "id": "N0Zrwtz9fGDF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(TimeDistributed(pretrained_mobilenet,input_shape=(x,y,z,channel)))\n",
        "\n",
        "model_2.add(TimeDistributed(BatchNormalization()))\n",
        "model_2.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "model_2.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model_2.add(GRU(128))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Dense(128,activation='relu'))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Dense(5, activation='softmax'))"
      ],
      "metadata": {
        "id": "NpADvt4KfULb"
      },
      "id": "NpADvt4KfULb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator2 = generator(train_path, train_doc, batch_size)\n",
        "val_generator2 = generator(val_path, val_doc, batch_size)\n",
        "\n",
        "optimiser = optimizers.Adam(lr=0.0001) #write your optimizer\n",
        "model_2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print(model_2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBTYV4VbfkC5",
        "outputId": "08a21da8-ac59-41c9-ba16-27c0f484d0b1"
      },
      "id": "hBTYV4VbfkC5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDist  (None, 30, 3, 3, 1024)    3228864   \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 30, 3, 3, 1024)    4096      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDi  (None, 30, 1, 1, 1024)    0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDi  (None, 30, 1024)          0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               443136    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3693253 (14.09 MB)\n",
            "Trainable params: 3669317 (14.00 MB)\n",
            "Non-trainable params: 23936 (93.50 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)  # write the REducelronplateau code here\n",
        "callbacks_list = [checkpoint, LR]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMOalJKtfsGo",
        "outputId": "8e35e320-cd1c-4e5f-8c3d-687e06c13017"
      },
      "id": "HMOalJKtfsGo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ],
      "metadata": {
        "id": "Kew3QUT8f04p"
      },
      "id": "Kew3QUT8f04p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_2.fit_generator(train_generator2, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator2,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOiVPYtDf6Sa",
        "outputId": "bf5c1198-3e76-4a4a-c1d4-0e6fad16621b"
      },
      "id": "WOiVPYtDf6Sa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e74d0b95d50a>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model_2.fit_generator(train_generator2, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
            "<ipython-input-6-502af651a6fd>:13: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/gdrive/MyDrive/Upgrad/RNN/Project_data/Project_data/train ; batch size = 10\n",
            "Epoch 1/25\n",
            "64/67 [===========================>..] - ETA: 1:12 - loss: 1.1394 - categorical_accuracy: 0.5484Batch:  67 Index: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-502af651a6fd>:38: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - ETA: 0s - loss: 1.1261 - categorical_accuracy: 0.5551 Source path =  /content/gdrive/MyDrive/Upgrad/RNN/Project_data/Project_data/val ; batch size = 10\n",
            "\n",
            "Epoch 1: saving model to model_init_2023-12-0412_48_39.221333/model-00001-1.12605-0.55505-0.73221-0.66000.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r67/67 [==============================] - 1714s 25s/step - loss: 1.1261 - categorical_accuracy: 0.5551 - val_loss: 0.7322 - val_categorical_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 1.2530 - categorical_accuracy: 0.4826\n",
            "Epoch 2: saving model to model_init_2023-12-0412_48_39.221333/model-00002-1.25299-0.48259-1.02965-0.58000.h5\n",
            "67/67 [==============================] - 558s 8s/step - loss: 1.2530 - categorical_accuracy: 0.4826 - val_loss: 1.0296 - val_categorical_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 1.0419 - categorical_accuracy: 0.6020\n",
            "Epoch 3: saving model to model_init_2023-12-0412_48_39.221333/model-00003-1.04188-0.60199-1.17982-0.57000.h5\n",
            "\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "67/67 [==============================] - 524s 8s/step - loss: 1.0419 - categorical_accuracy: 0.6020 - val_loss: 1.1798 - val_categorical_accuracy: 0.5700 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.9355 - categorical_accuracy: 0.6418\n",
            "Epoch 4: saving model to model_init_2023-12-0412_48_39.221333/model-00004-0.93552-0.64179-0.61771-0.70000.h5\n",
            "67/67 [==============================] - 548s 8s/step - loss: 0.9355 - categorical_accuracy: 0.6418 - val_loss: 0.6177 - val_categorical_accuracy: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 5/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.7571 - categorical_accuracy: 0.7015\n",
            "Epoch 5: saving model to model_init_2023-12-0412_48_39.221333/model-00005-0.75712-0.70149-0.39701-0.90000.h5\n",
            "67/67 [==============================] - 561s 8s/step - loss: 0.7571 - categorical_accuracy: 0.7015 - val_loss: 0.3970 - val_categorical_accuracy: 0.9000 - lr: 5.0000e-04\n",
            "Epoch 6/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.5948 - categorical_accuracy: 0.7910\n",
            "Epoch 6: saving model to model_init_2023-12-0412_48_39.221333/model-00006-0.59483-0.79104-0.43178-0.82000.h5\n",
            "67/67 [==============================] - 555s 8s/step - loss: 0.5948 - categorical_accuracy: 0.7910 - val_loss: 0.4318 - val_categorical_accuracy: 0.8200 - lr: 5.0000e-04\n",
            "Epoch 7/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.6580 - categorical_accuracy: 0.7861\n",
            "Epoch 7: saving model to model_init_2023-12-0412_48_39.221333/model-00007-0.65805-0.78607-0.45023-0.80000.h5\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "67/67 [==============================] - 559s 8s/step - loss: 0.6580 - categorical_accuracy: 0.7861 - val_loss: 0.4502 - val_categorical_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 8/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.4655 - categorical_accuracy: 0.8159\n",
            "Epoch 8: saving model to model_init_2023-12-0412_48_39.221333/model-00008-0.46549-0.81592-0.52538-0.76000.h5\n",
            "67/67 [==============================] - 552s 8s/step - loss: 0.4655 - categorical_accuracy: 0.8159 - val_loss: 0.5254 - val_categorical_accuracy: 0.7600 - lr: 2.5000e-04\n",
            "Epoch 9/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.3708 - categorical_accuracy: 0.8955\n",
            "Epoch 9: saving model to model_init_2023-12-0412_48_39.221333/model-00009-0.37081-0.89552-0.53826-0.80000.h5\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "67/67 [==============================] - 535s 8s/step - loss: 0.3708 - categorical_accuracy: 0.8955 - val_loss: 0.5383 - val_categorical_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 10/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.4431 - categorical_accuracy: 0.8507\n",
            "Epoch 10: saving model to model_init_2023-12-0412_48_39.221333/model-00010-0.44306-0.85075-0.45172-0.80000.h5\n",
            "67/67 [==============================] - 570s 9s/step - loss: 0.4431 - categorical_accuracy: 0.8507 - val_loss: 0.4517 - val_categorical_accuracy: 0.8000 - lr: 1.2500e-04\n",
            "Epoch 11/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.3058 - categorical_accuracy: 0.8856\n",
            "Epoch 11: saving model to model_init_2023-12-0412_48_39.221333/model-00011-0.30576-0.88557-0.41585-0.78000.h5\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "67/67 [==============================] - 565s 8s/step - loss: 0.3058 - categorical_accuracy: 0.8856 - val_loss: 0.4158 - val_categorical_accuracy: 0.7800 - lr: 1.2500e-04\n",
            "Epoch 12/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.2730 - categorical_accuracy: 0.8905\n",
            "Epoch 12: saving model to model_init_2023-12-0412_48_39.221333/model-00012-0.27304-0.89055-0.42894-0.78000.h5\n",
            "67/67 [==============================] - 564s 8s/step - loss: 0.2730 - categorical_accuracy: 0.8905 - val_loss: 0.4289 - val_categorical_accuracy: 0.7800 - lr: 6.2500e-05\n",
            "Epoch 13/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.3159 - categorical_accuracy: 0.8806\n",
            "Epoch 13: saving model to model_init_2023-12-0412_48_39.221333/model-00013-0.31589-0.88060-0.40288-0.81000.h5\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "67/67 [==============================] - 562s 8s/step - loss: 0.3159 - categorical_accuracy: 0.8806 - val_loss: 0.4029 - val_categorical_accuracy: 0.8100 - lr: 6.2500e-05\n",
            "Epoch 14/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.2611 - categorical_accuracy: 0.9204\n",
            "Epoch 14: saving model to model_init_2023-12-0412_48_39.221333/model-00014-0.26109-0.92040-0.31025-0.84000.h5\n",
            "67/67 [==============================] - 567s 8s/step - loss: 0.2611 - categorical_accuracy: 0.9204 - val_loss: 0.3103 - val_categorical_accuracy: 0.8400 - lr: 3.1250e-05\n",
            "Epoch 15/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.2374 - categorical_accuracy: 0.9254\n",
            "Epoch 15: saving model to model_init_2023-12-0412_48_39.221333/model-00015-0.23742-0.92537-0.40235-0.77000.h5\n",
            "67/67 [==============================] - 564s 8s/step - loss: 0.2374 - categorical_accuracy: 0.9254 - val_loss: 0.4024 - val_categorical_accuracy: 0.7700 - lr: 3.1250e-05\n",
            "Epoch 16/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.2007 - categorical_accuracy: 0.9303\n",
            "Epoch 16: saving model to model_init_2023-12-0412_48_39.221333/model-00016-0.20066-0.93035-0.37320-0.79000.h5\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "67/67 [==============================] - 563s 8s/step - loss: 0.2007 - categorical_accuracy: 0.9303 - val_loss: 0.3732 - val_categorical_accuracy: 0.7900 - lr: 3.1250e-05\n",
            "Epoch 17/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.2223 - categorical_accuracy: 0.9254\n",
            "Epoch 17: saving model to model_init_2023-12-0412_48_39.221333/model-00017-0.22231-0.92537-0.39465-0.78000.h5\n",
            "67/67 [==============================] - 630s 9s/step - loss: 0.2223 - categorical_accuracy: 0.9254 - val_loss: 0.3947 - val_categorical_accuracy: 0.7800 - lr: 1.5625e-05\n",
            "Epoch 18/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.2094 - categorical_accuracy: 0.9502\n",
            "Epoch 18: saving model to model_init_2023-12-0412_48_39.221333/model-00018-0.20943-0.95025-0.43866-0.76000.h5\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "67/67 [==============================] - 558s 8s/step - loss: 0.2094 - categorical_accuracy: 0.9502 - val_loss: 0.4387 - val_categorical_accuracy: 0.7600 - lr: 1.5625e-05\n",
            "Epoch 19/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.2059 - categorical_accuracy: 0.9204\n",
            "Epoch 19: saving model to model_init_2023-12-0412_48_39.221333/model-00019-0.20592-0.92040-0.37579-0.81000.h5\n",
            "67/67 [==============================] - 562s 8s/step - loss: 0.2059 - categorical_accuracy: 0.9204 - val_loss: 0.3758 - val_categorical_accuracy: 0.8100 - lr: 7.8125e-06\n",
            "Epoch 20/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.1690 - categorical_accuracy: 0.9502\n",
            "Epoch 20: saving model to model_init_2023-12-0412_48_39.221333/model-00020-0.16902-0.95025-0.37113-0.83000.h5\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "67/67 [==============================] - 610s 9s/step - loss: 0.1690 - categorical_accuracy: 0.9502 - val_loss: 0.3711 - val_categorical_accuracy: 0.8300 - lr: 7.8125e-06\n",
            "Epoch 21/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.1774 - categorical_accuracy: 0.9403\n",
            "Epoch 21: saving model to model_init_2023-12-0412_48_39.221333/model-00021-0.17742-0.94030-0.37296-0.81000.h5\n",
            "67/67 [==============================] - 576s 9s/step - loss: 0.1774 - categorical_accuracy: 0.9403 - val_loss: 0.3730 - val_categorical_accuracy: 0.8100 - lr: 3.9063e-06\n",
            "Epoch 22/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.1403 - categorical_accuracy: 0.9751\n",
            "Epoch 22: saving model to model_init_2023-12-0412_48_39.221333/model-00022-0.14031-0.97512-0.37496-0.80000.h5\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "67/67 [==============================] - 644s 10s/step - loss: 0.1403 - categorical_accuracy: 0.9751 - val_loss: 0.3750 - val_categorical_accuracy: 0.8000 - lr: 3.9063e-06\n",
            "Epoch 23/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.2345 - categorical_accuracy: 0.9104\n",
            "Epoch 23: saving model to model_init_2023-12-0412_48_39.221333/model-00023-0.23454-0.91045-0.35451-0.82000.h5\n",
            "67/67 [==============================] - 655s 10s/step - loss: 0.2345 - categorical_accuracy: 0.9104 - val_loss: 0.3545 - val_categorical_accuracy: 0.8200 - lr: 1.9531e-06\n",
            "Epoch 24/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.2300 - categorical_accuracy: 0.9204\n",
            "Epoch 24: saving model to model_init_2023-12-0412_48_39.221333/model-00024-0.23000-0.92040-0.37463-0.82000.h5\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "67/67 [==============================] - 600s 9s/step - loss: 0.2300 - categorical_accuracy: 0.9204 - val_loss: 0.3746 - val_categorical_accuracy: 0.8200 - lr: 1.9531e-06\n",
            "Epoch 25/25\n",
            "67/67 [==============================] - ETA: 0s - loss: 0.1391 - categorical_accuracy: 0.9652\n",
            "Epoch 25: saving model to model_init_2023-12-0412_48_39.221333/model-00025-0.13914-0.96517-0.43439-0.78000.h5\n",
            "67/67 [==============================] - 560s 8s/step - loss: 0.1391 - categorical_accuracy: 0.9652 - val_loss: 0.4344 - val_categorical_accuracy: 0.7800 - lr: 9.7656e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(history):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
        "    axes[0].plot(history.history['loss'])\n",
        "    axes[0].plot(history.history['val_loss'])\n",
        "    axes[0].legend(['loss','val_loss'])\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')"
      ],
      "metadata": {
        "id": "N7Vd81stbh30"
      },
      "id": "N7Vd81stbh30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "sYT2Qqb6bkcL",
        "outputId": "74d1695a-9bc9-4944-bc5e-a262097a8b73"
      },
      "id": "sYT2Qqb6bkcL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABMkAAAF4CAYAAABO/q7jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACHqElEQVR4nOzdeVxV1frH8c85h1kBRWRQUZxn0RwQzdSibLiW2WBZWZYNXutW3n6VDdpw0263ut3SsmywybQsbdAs05wSNQdMc0YEHEBBBQWZzjm/P7agJCoHzgDyfb9e58Vmn733eo4rbPG41rNMdrvdjoiIiIiIiIiISC1m9nQAIiIiIiIiIiIinqYkmYiIiIiIiIiI1HpKkomIiIiIiIiISK2nJJmIiIiIiIiIiNR6SpKJiIiIiIiIiEitpySZiIiIiIiIiIjUekqSiYiIiIiIiIhIrackmYiIiIiIiIiI1HpKkomIiIiIiIiISK2nJJmIiIiIiIiIiNR6SpKJiIiICADLli1j8ODBNGrUCJPJxNy5c897z5IlS7jooovw9fWlVatWTJ8+3eVxioiIiLiCkmQiIiIiAkBubi4xMTFMmTKlQtcnJydzzTXXMHDgQBITE3nkkUcYNWoUP/30k4sjFREREXE+k91ut3s6CBERERGpXkwmE3PmzGHIkCFnveaJJ55g3rx5bN68ufTcLbfcwtGjR1mwYIEbohQRERFxHi9PB1ARNpuN/fv3ExgYiMlk8nQ4IiIiUgPY7XaOHTtGo0aNMJs1ed4VEhISiI+PL3Nu0KBBPPLII2e9p6CggIKCgtLvbTYbhw8fpkGDBhrniYiISIW4apxXI5Jk+/fvJyoqytNhiIiISA2UlpZGkyZNPB3GBSk9PZ3w8PAy58LDw8nJyeHEiRP4+/ufcc+kSZN4/vnn3RWiiIiIXMCcPc6rEUmywMBAwPjwQUFBHo5GREREaoKcnByioqJKxxFSPYwbN46xY8eWfp+dnU3Tpk01zhMREZEKc9U4r0YkyUqm3gcFBWnwJCIiIg7REj7XiYiIICMjo8y5jIwMgoKCyp1FBuDr64uvr+8Z5zXOExEREUc5e5ynAh0iIiIiUilxcXEsWrSozLmFCxcSFxfnoYhEREREKk9JMhEREREB4Pjx4yQmJpKYmAhAcnIyiYmJpKamAsZSyREjRpRe/8ADD7B7924ef/xxtm3bxttvv82XX37Jo48+6onwRURERKpESTIRERERAWDt2rV069aNbt26ATB27Fi6devG+PHjAThw4EBpwgygefPmzJs3j4ULFxITE8Nrr73G+++/z6BBgzwSv4iIiEhVmOx2u93TQZxPTk4OwcHBZGdnq1aFiIh4hN1up7i4GKvV6ulQ5CSLxYKXl9dZa1Fo/FAzqJ9ERETEUa4aP9SIwv0iIiKeVFhYyIEDB8jLy/N0KPIXAQEBREZG4uPj4+lQRERERKSGU5JMRETkHGw2G8nJyVgsFho1aoSPj492S6wG7HY7hYWFHDp0iOTkZFq3bo3ZrCoSIiIiIlJ5SpKJiIicQ2FhITabjaioKAICAjwdjpzG398fb29vUlJSKCwsxM/Pz9MhiYiIiEgNpn9yFRERqQDNUqqe1C8iIiIi4iwaWYqIiIiIiIiISK2nJJkL/Lk/m6N5hZ4OQ0REREREREREKkhJMiebv+kA17y5gvs+XefpUEREpJYbMGAAjzzyiKfDEBERERGpEZQkc6LsE0VM+O5PANYkH2ZnxjEPRyQiIiIiIiIiIhWhJJkTvbJgG4eOFZR+P3vdXg9GIyIiIiIiIiIiFaUkmZOsSznM56tTAbi7b3MAvtmwj2KrzZNhiYiIk9ntdvIKiz3ystvtlY77yJEjjBgxgvr16xMQEMBVV13Fzp07S99PSUlh8ODB1K9fnzp16tCxY0fmz59feu9tt91Gw4YN8ff3p3Xr1nz00UdV/rMUEREREalOvDwdwIWgyGrjqW82A3BT9yaMu7od3ybu49CxApbtPMSl7cI9HKGIiDjLiSIrHcb/5JG2t7wwiACfyv2v+6677mLnzp189913BAUF8cQTT3D11VezZcsWvL29GTNmDIWFhSxbtow6deqwZcsW6tatC8Czzz7Lli1b+PHHHwkNDWXXrl2cOHHCmR9NRERERMTjlCRzgveW7WZ7xjFC6vjw1NXt8baYua5rYz78LZmv1u5VkkxERDyqJDn222+/0adPHwA+//xzoqKimDt3LjfddBOpqanccMMNdO7cGYAWLVqU3p+amkq3bt3o0aMHANHR0W7/DCIiIiIirqYkWRWlZOXy5iJjucoz17Snfh0fAG7q0YQPf0vml60ZHMktLD0vIiI1m7+3hS0vDPJY25WxdetWvLy8iI2NLT3XoEED2rZty9atWwH4xz/+wejRo/n555+Jj4/nhhtuoEuXLgCMHj2aG264gfXr13PFFVcwZMiQ0mSbiIiIiMiFQjXJqsBut/PM3M0UFNvo26oB13drXPpe+8ggOjYKoshq59vEfR6MUkREnMlkMhHg4+WRl8lkctnnGjVqFLt37+aOO+5g06ZN9OjRg7feeguAq666ipSUFB599FH279/PZZddxmOPPeayWEREREREPEFJsir4NnE/y3dm4uNl5qUhnc/45eWm7k0AmL1eu1yKiIjntG/fnuLiYlavXl16Lisri+3bt9OhQ4fSc1FRUTzwwAN88803/POf/2TatGml7zVs2JA777yTzz77jDfeeIP33nvPrZ9BRERERMTVlCSrpKN5hbz4wxYA/nFpK6JD65xxzXVdG+NtMbF5Xw5bD+S4O0QREREAWrduzXXXXce9997LihUr2LhxI7fffjuNGzfmuuuuA+CRRx7hp59+Ijk5mfXr1/Prr7/Svn17AMaPH8+3337Lrl27+PPPP/nhhx9K3xMRERERuVA4nCRbtmwZgwcPplGjRphMJubOnXvO67/55hsuv/xyGjZsSFBQEHFxcfz0k2d2BXOmSfO3kZVbSOuwutx3Sctyr6lfx4f49kbR/tnrNJtMREQ856OPPqJ79+787W9/Iy4uDrvdzvz58/H29gbAarUyZswY2rdvz5VXXkmbNm14++23AfDx8WHcuHF06dKFSy65BIvFwsyZMz35cUREREREnM7hwv25ubnExMRw9913M3To0PNev2zZMi6//HImTpxIvXr1+Oijjxg8eDCrV6+mW7dulQra01bvzmLW2jQAJg7tjI/X2XONN/Vowo+b05m7YR9PXtUOb4sm74mIiHssWbKk9Lh+/fp88sknZ722pP5YeZ555hmeeeYZZ4YmIiIiIlLtOJwku+qqq7jqqqsqfP0bb7xR5vuJEyfy7bff8v3339fIJFlBsZWn5mwC4NZeTekZHXLO6y9p3ZCGgb4cOlbAr9sOckXHCHeEKSIiIiIiIiIiDnD7tCabzcaxY8cICTl7cqmgoICcnJwyr+pi6pLdJB3KJbSuL09e2e6813tZzAw9uevlV1pyKSIiIiIiIiJSLbk9Sfbqq69y/Phxbr755rNeM2nSJIKDg0tfUVFRbozw7HYfOs6UX3cBMH5wB4IDvCt0340nd7n8ddtBMo8XuCw+ERERERERERGpHLcmyWbMmMHzzz/Pl19+SVhY2FmvGzduHNnZ2aWvtLQ0N0ZZPrvdztNzNlNotdG/TUMGd4ms8L2twwOJiapHsc3O3A37XBiliIiIiIiIiIhUhtuSZDNnzmTUqFF8+eWXxMfHn/NaX19fgoKCyrw87ev1+0jYnYWft5l/DemEyWRy6P6S2WSz1+3Fbre7IkQREREREREREakktyTJvvjiC0aOHMkXX3zBNddc444mnepwbiEvzdsCwCPxbYgKCXD4Gdd2aYSPl5lt6cf4c3/1qbEmIiIiIiIiIiKVSJIdP36cxMREEhMTAUhOTiYxMZHU1FTAWCo5YsSI0utnzJjBiBEjeO2114iNjSU9PZ309HSys7Od8wnc4F/ztnAkr4h2EYHcc3HzSj0jOMCbQSd3tvxqrQPLR3P2w/uXw29vVqpdERERERERERE5P4eTZGvXrqVbt25069YNgLFjx9KtWzfGjx8PwIEDB0oTZgDvvfcexcXFjBkzhsjIyNLXww8/7KSP4Ford2Xyzfp9mEwwaWhnvC2Vn3xXsuTy2437KSi2VuymX1+CvWtgzXuVbldERERERERERM7Ny9EbBgwYcM6aWtOnTy/z/ZIlSxxtotrIL7Ly9NzNANzRuxndmtav0vMubhVKRJAf6Tn5LNp6kKs7n6f4/6HtkDjDOM7eC0X54O1XpRhERERERERERORMbt3dsqZ5+9ddJGfmEhboy2OD2lb5eRaziaEXNQYquORy8Ytgt538xg5HU6ocg4iISEVFR0fzxhtvVOhak8nE3LlzXRqPiIiIiIgrKUl2FjszjvHO0iQAnr+2I0F+3k55bsmSy6U7DnEwJ//sF+5dB1u/B0xQJ8w4l5XklBhERERERERERKQsJcnKYbPZeWrOJoqsdi5rF8aVnSKc9uwWDevSvVl9bHb4ZsO+s1+46Hnja8ytEN3XOD6822lxiIiIiIiIiIjIKUqSlePLtWn8vucIAT4WXhjSCZPJ5NTn33RyNtnsdXvLr++W9CskLwWLDwx4EkJaGOeVJBMR8Ty7HQpzPfM6R03Qv3rvvfdo1KgRNputzPnrrruOu+++m6SkJK677jrCw8OpW7cuPXv25JdffnHaH9OmTZu49NJL8ff3p0GDBtx3330cP3689P0lS5bQq1cv6tSpQ7169ejbty8pKUZZgY0bNzJw4EACAwMJCgqie/furF271mmxiYiIiIiUx+HC/Re6Q8cKmDh/KwBjL29D43r+Tm/jmi6RPPf9n+w6eJzEtKNlNwSw20/NIutxD9RvBiEtje+VJBMR8byiPJjYyDNtP7UffOpU6NKbbrqJhx56iF9//ZXLLrsMgMOHD7NgwQLmz5/P8ePHufrqq3nppZfw9fXlk08+YfDgwWzfvp2mTZtWKczc3FwGDRpEXFwcv//+OwcPHmTUqFE8+OCDTJ8+neLiYoYMGcK9997LF198QWFhIWvWrCn9R6nbbruNbt268c4772CxWEhMTMTb2zllD0REREREzkZJsr/417wt5OQX06lxEHf1iXZJG4F+3lzVKZI5G/Yxe93eskmyrd/B/g3gXQf6/dM4VzqTTDXJRESkYurXr89VV13FjBkzSpNks2fPJjQ0lIEDB2I2m4mJiSm9/sUXX2TOnDl89913PPjgg1Vqe8aMGeTn5/PJJ59Qp46R1Js8eTKDBw/m3//+N97e3mRnZ/O3v/2Nli2Nfwhq37596f2pqan83//9H+3atQOgdevWVYpHRERERKQilCQ7zdIdh/g2cT9mE0y6vgteFtetRr2xexPmbNjHdxv38+zfOuDnbQFrMSx60bigz4NQt6FxXJIky94LxQXg5euyuERE5Dy8A4wZXZ5q2wG33XYb9957L2+//Ta+vr58/vnn3HLLLZjNZo4fP85zzz3HvHnzOHDgAMXFxZw4cYLU1NQqh7l161ZiYmJKE2QAffv2xWazsX37di655BLuuusuBg0axOWXX058fDw333wzkZGRAIwdO5ZRo0bx6aefEh8fz0033VSaTBMRERERcRXVJDvpRKGVZ+ZuAuDOPtF0bhLs0vbiWjSgcT1/juUX8/OWDOPkxhmQtRP8QyDutH/FrxsGPnXBboOjVf/lRUREqsBkMpY8euLlYI3MwYMHY7fbmTdvHmlpaSxfvpzbbrsNgMcee4w5c+YwceJEli9fTmJiIp07d6awsNAVf2pn+Oijj0hISKBPnz7MmjWLNm3asGrVKgCee+45/vzzT6655hoWL15Mhw4dmDNnjlviEhEREZHaS0myk95cvJO0wyeIDPbjn1e0dXl7ZrOJG04W8P9qbRoU5cOSl403L3kM/IJOXWwyQUhz4zhLSy5FRKRi/Pz8GDp0KJ9//jlffPEFbdu25aKLLgLgt99+46677uL666+nc+fOREREsGfPHqe02759ezZu3Ehubm7pud9++w2z2Uzbtqf+H9utWzfGjRvHypUr6dSpEzNmzCh9r02bNjz66KP8/PPPDB06lI8++sgpsYmIiIiInI2SZMC29BymLTOK4j9/bUfq+rpnFeqNFxlJshW7Msle/g7k7IOgJkbB/r/SDpciIlIJt912G/PmzePDDz8snUUGRp2vb775hsTERDZu3Mjw4cPP2AmzKm36+flx5513snnzZn799Vceeugh7rjjDsLDw0lOTmbcuHEkJCSQkpLCzz//zM6dO2nfvj0nTpzgwQcfZMmSJaSkpPDbb7/x+++/l6lZJiIiIiLiCrW+JpnNZmfcN5sottkZ1DGcKzpGuK3tpg0CiG0ewpbkvfis/K9xcsCT4O135sVKkomISCVceumlhISEsH37doYPH156/vXXX+fuu++mT58+hIaG8sQTT5CTk+OUNgMCAvjpp594+OGH6dmzJwEBAdxwww28/vrrpe9v27aNjz/+mKysLCIjIxkzZgz3338/xcXFZGVlMWLECDIyMggNDWXo0KE8//zzTolNRERERORsan2SbMaaVDakHqWurxfPX9vJ7e3f2L0J+9Pexb84G3toG0wxt5Z/oZJkIiJSCWazmf37z9xoIDo6msWLF5c5N2bMmDLfO7L80m63l/m+c+fOZzy/RHh4+FlrjPn4+PDFF19UuF0REREREWep9Umy/m0a0r9NQwa2bUhEcDkzuFzs6hZemCzzAUjq/CitLGfpkpCTu3odVk0yERERERERERFnq/U1yaJCApg+sicj4qI90n6d1W8QYCog0daCaQc7nv3CkplkR1Oh2D07j4mIiAB8/vnn1K1bt9xXx47n+H+XiIiIiEgNUutnkgGYTCZMJg80fCQFfv8AgFeKb+GPzelMuK4jAT7ldEtgBHj5Q/EJyE6DBi3dHKyIiNRW1157LbGxseW+5+3t7eZoRERERERcQ0kyT1oyCWxF2FsMYG96L44fzmPB5nSGntz1sgyTyZhNdvBPoy6ZkmQiIuImgYGBBAYGejoMERERERGXqvXLLT0mYwtsnAmA6bLx3NjdSIx9tXbv2e9pcHLJZZbqkomIuNtfC9NL9aB+ERERERFnUZLMUxb/C7BD+2uhcXdu6N4EkwkSdmeRdjiv/Hu0w6WIiNuVLCfMyzvL383iUSX9omWfIiIiIlJVWm7pCWlrYPs8MJnh0mcBaFzPnz4tG/Dbriy+Xr+XR+LbnHmfkmQiIm5nsVioV68eBw8eBCAgIACTRwpZyunsdjt5eXkcPHiQevXqYbFYPB2SiIiIiNRwSpK5m90OvzxvHHe9DRqeSobd1D2qNEn2j0tbYzb/5ZcwJclERDwiIiICoDRRJtVHvXr1SvtHRERERKQqlCRzt6RFkLICLL4w4Mkybw3qGEGgrxdph0+wOvkwcS0blL035GSx/qMpYC0Gi7pPRMQdTCYTkZGRhIWFUVRU5Olw5CRvb2/NIBMRERERp1GWxZ1stlOzyHrdC8Fld7H097Hwt5hIvliTxux1e89MkgVGgpcfFOdDduqpmWUiIuIWFotFSRkRERERkQuUCve705Y5kP4H+ATCxWPLvaRkl8v5mw5wvKC47JtmM9RvbhxryaWIiIiIiIiIiNMoSeYu1iJY/JJx3PcfUKdBuZdd1LQ+LULrcKLIyvxNB868oMHJJZeHk10UqIiIiIiIiIhI7aMkmbts+AwOJ0FAKPQefdbLTCYTN5ycTTZ77d4zLwg5OZMsK8kVUYqIiEgtN2XKFKKjo/Hz8yM2NpY1a9ac8/o33niDtm3b4u/vT1RUFI8++ij5+fluilZERETEeZQkc4fCPFj6b+P4kv8D38BzXn7DRU0wm2DNnsPsycwt+6Z2uBQREREXmTVrFmPHjmXChAmsX7+emJgYBg0adNadXWfMmMGTTz7JhAkT2Lp1Kx988AGzZs3iqaeecnPkIiIiIlWnJJk7rHkPjh2A4KbQY+R5L48I9qNf64YAfL3+L7PJlCQTERERF3n99de59957GTlyJB06dGDq1KkEBATw4Ycflnv9ypUr6du3L8OHDyc6OporrriCW2+99ZyzzwoKCsjJySnzEhEREakOlCRztRNHYcV/jeOBT4GXb4VuKyng//W6vVht9lNvhJysSXZkD9iszotTREREarXCwkLWrVtHfHx86Tmz2Ux8fDwJCQnl3tOnTx/WrVtXmhTbvXs38+fP5+qrrz5rO5MmTSI4OLj0FRUV5dwPIiIiIlJJSpK52so3If8oNGwPXW6u8G2XdwgnyM+L/dn5JCRlnXojqDFYfMFWBNlpzo9XREREaqXMzEysVivh4eFlzoeHh5Oenl7uPcOHD+eFF17g4osvxtvbm5YtWzJgwIBzLrccN24c2dnZpa+0NI1nREREpHpQksyVjmXAqneM48ueBbOlwrf6eVu4tmsjAL5ad9rg0WyG+tHGsZZcioiIiActWbKEiRMn8vbbb7N+/Xq++eYb5s2bx4svvnjWe3x9fQkKCirzEhEREakOlCRzpWX/gaI8aNIT2p592cHZ3NTdWH6wYHM6OflFp95QXTIRERFxstDQUCwWCxkZGWXOZ2RkEBERUe49zz77LHfccQejRo2ic+fOXH/99UycOJFJkyZhs9ncEbaIiIiI0yhJ5iqHk2HdR8Zx/HNgMjn8iC5NgmkdVpeCYhs/bDxw6o0GJ+uSZSlJJiIiIs7h4+ND9+7dWbRoUek5m83GokWLiIuLK/eevLw8zOayw0mLxZg5b7fby7tFREREpNpSksxVfp0ItmJoeRlEX1ypR5hMJm7qYRTw//C3ZPKLThbqD2lufNVMMhEREXGisWPHMm3aND7++GO2bt3K6NGjyc3NZeRIY3fuESNGMG7cuNLrBw8ezDvvvMPMmTNJTk5m4cKFPPvsswwePLg0WSYiIiJSU3h5OoALUvpm2PSVcXzZ+Co96qbuUby3LJldB4/z/Pd/MmloFy23FBEREZcYNmwYhw4dYvz48aSnp9O1a1cWLFhQWsw/NTW1zMyxZ555BpPJxDPPPMO+ffto2LAhgwcP5qWXXvLURxARERGpNJO9BsyFz8nJITg4mOzs7JpR3HXGMNixADoOhZs+qvLjftuVye0frMZuhzeGdWVIdBH8LwYsPvB0ukMbAoiIiNQWNW78UEupn0RERMRRrho/aLmls+1PNBJkJgtc+oxTHtm3VSgPXdoagKfmbCKpsD6YvcFaCDn7nNKGiIiIiIiIiEhtpiSZs+1YYHxtd82pAvtO8PBlrendIoS8QitjvtiIrX608YaWXIqIiIiIiIiIVJmSZM62e4nxtdVlTn2sxWzizVu6EVrXh23px9hR2NB4Q0kyEREREREREZEqU5LMmQqOwd7fjeMWA5z++LAgP/47rCsmE6w8cnLNrZJkIiIiIiIiIiJVpiSZM+35DWzFUL85lCyHdLJ+rRvy0MBWJNsjAMg9sMMl7YiIiIiIiIiI1CYOJ8mWLVvG4MGDadSoESaTiblz5573niVLlnDRRRfh6+tLq1atmD59eiVCrQF2/2p8dcEsstM9HN8G//BWABxK2Up+kdWl7YmIiIiIiIiIXOgcTpLl5uYSExPDlClTKnR9cnIy11xzDQMHDiQxMZFHHnmEUaNG8dNPPzkcbLVXUo+s5UCXNmMxm7hvyOUARFgP8OL3m13anoiIiIiIiIjIhc7L0RuuuuoqrrrqqgpfP3XqVJo3b85rr70GQPv27VmxYgX//e9/GTRoULn3FBQUUFBQUPp9Tk6Oo2G6X85+OLQNMEHzS1zeXGjjVthMXvhRxKI1G4lt2ZBrYxq5vF0RERERERERkQuRy2uSJSQkEB8fX+bcoEGDSEhIOOs9kyZNIjg4uPQVFRXl6jCrbvdS42ujbuBf3/XtWbww128GQHNzOuO+/oPkzFzXtysiIiIiIiIicgFyeZIsPT2d8PDwMufCw8PJycnhxIkT5d4zbtw4srOzS19paWmuDrPqSuqRuXipZRkhLQAY0PA4uYVW/v75etUnExERERERERGphGq5u6Wvry9BQUFlXtWa3X6qHpmLi/aXcTJJdltrKyF1fNh6IId/zdvivvZFRERERERERC4QLk+SRUREkJGRUeZcRkYGQUFB+Pv7u7p59zi4FY5ngJc/RMW6r90GLQGom5vCf4d1BeCzVan88Md+98UgIiIiIiIiInIBcHmSLC4ujkWLFpU5t3DhQuLi4lzdtPuUzCJr1ge8fN3X7smZZGTtpn+bhowZaCTNnvx6E3tUn0xEREREREREpMIcTpIdP36cxMREEhMTAUhOTiYxMZHU1FTAqCc2YsSI0usfeOABdu/ezeOPP862bdt4++23+fLLL3n00Ued8wmqA0/UI4NTSbLDu8Fu59H4NvSKDuF4QTFjZqg+mYiIiIiIiIhIRTmcJFu7di3dunWjW7duAIwdO5Zu3boxfvx4AA4cOFCaMANo3rw58+bNY+HChcTExPDaa6/x/vvvM2jQICd9BA8rLoQ9vxnH7qxHBlCvKZgsUHwCjqXjZTHzv1u7ElLHhz/35/DSvK3ujUdEREREREREpIbycvSGAQMGYLfbz/r+9OnTy71nw4YNjjZVM+z9HYpyoU5DCOvo3rYt3kai7EiyMZssKJLIYH9evzmGuz76nU9XpdC7RQOu6RLp3rhERERERERERGqYarm7ZY1SstSyeX8we+CPs3TJZVLpqQFtwxg9wKhP9sTXf6g+mYiIiIiIiIjIeShJVlUlRfvdXY+sxOl1yU7zz8vb0KNZfY4XFPPgF+spKFZ9MhERERERERGRs1GSrCpOHIV964xjd9cjK3GWJJmXxcxbw7tRP8CbzftymKj6ZCIiIiIiIiIiZ6UkWVXsWQF2GzRoDcFNPBNDA2NZJVm7z3jLqE/WFYCPE1KYv+mAGwMTEREREREREak5lCSripJ6ZJ6aRQZlZ5KVs6HCwHZhPND/ZH2y2X+QkqX6ZCIiIiIiIiIif6UkWVV4uh4ZGLtbmszGDpvHD5Z7yT+vaEP3ZvU5VlDMgzM2qD6ZiIiIiIiIiMhfKElWWUfTIGsXmCwQfbHn4vDyPbXU8/CZSy4BvC1m3rq1G/UCvNm0L5tJ87e5MUARERERERERkepPSbLKKplF1rg7+AV7NBRCTtYlO5x01ksa1fPn9ZtjAJi+cg8/qj6ZiIiIiIiIiEgpJckqqzrUIytxlh0u/+rSduHcf4lx7XPf/0lhsc3VkYmIiIiIiIiI1AhKklWGzQa7lxrHnqxHVqKCSTKAsVe0ISzQl4ycAuZt2u/iwEREREREREREagYlySojYzPkZYJPXWjS09PRQIOS5ZbnT5L5elm4s080AO8vT8Zezo6YIiIiIiIiIiK1jZJklVFSj6xZX7B4ezQU4NRMsqzdUIGk1/BeTfHzNvPn/hxW7T7s4uBERERERERERKo/Jckqo6QeWXVYaglQrxlggsJjkJt53svr1/Hhpu5RALy//Pyzz0RERERERERELnRKkjmqKB9SEozj6lC0H8DbD4KbGMcVWHIJMLJvNCYTLNp2kKRDx10YnIiIiIiIiIhI9ackmaPSVkPxCagbAQ3beTqaUxwo3g/QomFdLmsXDsCHK5JdFZWIiIiIiIiISI2gJJmjSuqRtRgAJpMnIymrNEmWVOFbRvVrDsDsdXs5nFvoiqhERERERERERGoEJckcVd3qkZVwcCYZQGzzEDo3Dqag2Mbnq1JcFJiIiIiIiIiISPWnJJkj8g7D/kTjuHl/j4ZyhkokyUwmU+lsso8TUigotroiMhERERERERGRak9JMkckLwPs0LA9BEV6OpqyGrQ0vmbtBru9wrdd3TmSiCA/Mo8X8F3ifhcFJyIiIiIiIiJSvSlJ5oiSpZbVZVfL09WPNr4WZBsz3irI22Lmrr7GvR+sSMbuQIJNRERERERERORCoSSZI0qK9le3emQA3v4Q1Ng4dmDJJcCtvZoS4GNhW/oxVuzKdEFwIiIiIiIiIiLVm5JkFXU4GY7sAbMXNOvj6WjKV4m6ZADB/t7c3CMKgPeXJzs7KhERERERERGRak9JsooqmUXWpBf4Bno0lLOqZJIM4O6+zTGZYOmOQ+zIOObkwEREREREREREqjclySqqOtcjK1GaJEty+NamDQIY1CECgA80m0xEREREREREahklySrCZj25syXVsx5ZiSrMJAO495LmAMxJ3MehYwXOikpEREREREREpNpTkqwiDmyEE0fANwgaXeTpaM6uikmyi5rWp2tUPQqLbXy2KsWJgYmIiIiIiIiIVG9KklVEST2y6H5g8fJoKOcUYswE48QRyDvs8O0mk4lR/YxnfLYqhfwiqzOjExERERERERGptpQkq4iaUI8MwKcOBEYax4crV1fsyo4RNK7nT1ZuIXM27HNicCIiIiIiIiIi1ZeSZOdTmAepq4zj6lyPrEQVl1x6WcyM7BsNwAcrkrHZ7E4KTERERERERESk+lKS7HxSE8BaCEFNoEErT0dzfiVLLiuZJAMY1jOKur5e7Dp4nKU7DzkpMBERERERERGR6ktJsvMpqUfWYgCYTJ6MpGJCWhpfDydV+hGBft7c0jMKgA+WV27ZpoiIiIiIiIhITaIk2fmU1COrCUstocrLLUvc1Tcai9nEil2ZbNmf44TARERERERERESqLyXJziU3E9I3GcfN+3s2lopyUpKsSf0AruoUARi1yURERERERERELmRKkp1LyVLL8M5Qt6FHQ6mwkiRZXhacOFqlR43qZzzru437OJiTX8XARERERERERESqLyXJzqVkqWWLGjKLDMC3LtQNN46rOJusa1Q9ejSrT5HVzicJKU4ITkRERKq7KVOmEB0djZ+fH7GxsaxZs+ac1x89epQxY8YQGRmJr68vbdq0Yf78+W6KVkRERMR5lCQ7G7sdkpYYxzWlHlkJJy25hFOzyT5bnUJeYXGVnyciIiLV16xZsxg7diwTJkxg/fr1xMTEMGjQIA4ePFju9YWFhVx++eXs2bOH2bNns337dqZNm0bjxo3dHLmIiIhI1SlJdjZZSZCzFyw+0LSPp6NxTGmSrOq1xC7vEE7TkACO5hXx9fp9VX6eiIiIVF+vv/469957LyNHjqRDhw5MnTqVgIAAPvzww3Kv//DDDzl8+DBz586lb9++REdH079/f2JiYtwcuYiIiEjVKUl2NiVLLaNiwSfAs7E4yokzySxmE3f3jQbgwxXJ2Gz2Kj9TREREqp/CwkLWrVtHfHx86Tmz2Ux8fDwJCQnl3vPdd98RFxfHmDFjCA8Pp1OnTkycOBGr1XrWdgoKCsjJySnzEhEREakOlCQ7m5Ki/S0GeDKKyilNkiU55XE39YgiyM+L5MxcFm8rf7mFiIiI1GyZmZlYrVbCw8PLnA8PDyc9Pb3ce3bv3s3s2bOxWq3Mnz+fZ599ltdee41//etfZ21n0qRJBAcHl76ioqKc+jlEREREKqtSSTJHC7q+8cYbtG3bFn9/f6Kionj00UfJz6/GuyVaiyF5uXFc0+qRgVNnkgHU8fVieGwzAKYtd84zRUREpOaz2WyEhYXx3nvv0b17d4YNG8bTTz/N1KlTz3rPuHHjyM7OLn2lpaW5MWIRERGRs3M4SeZoQdcZM2bw5JNPMmHCBLZu3coHH3zArFmzeOqpp6ocvMvs3wAF2eBXDyK7ejoax5UkyXIPQb5zljDc2acZXmYTq5MPs2lvtlOeKSIiItVHaGgoFouFjIyMMuczMjKIiIgo957IyEjatGmDxWIpPde+fXvS09MpLCws9x5fX1+CgoLKvERERESqA4eTZI4WdF25ciV9+/Zl+PDhREdHc8UVV3Drrbeed/aZR5UstWx+CZgt57y0WvILgjoNjeMjVS/eDxAZ7M/fukQC8MEKzSYTERG50Pj4+NC9e3cWLVpUes5ms7Fo0SLi4uLKvadv377s2rULm81Wem7Hjh1ERkbi4+Pj8phFREREnMmhJFllCrr26dOHdevWlSbFdu/ezfz587n66qvP2o7HC7qWFO2vifXISpTMJstyTl0ygFH9jGf+8McBDmSfcNpzRUREpHoYO3Ys06ZN4+OPP2br1q2MHj2a3NxcRo4cCcCIESMYN25c6fWjR4/m8OHDPPzww+zYsYN58+YxceJExowZ46mPICIiIlJpXo5cfK6Crtu2bSv3nuHDh5OZmcnFF1+M3W6nuLiYBx544JzLLSdNmsTzzz/vSGjOU3Ac0k7OcquJ9chKhLSAtNVOq0sG0KlxML1bhLBq92Gmr9zDuKvaO+3ZIiIi4nnDhg3j0KFDjB8/nvT0dLp27cqCBQtKx36pqamYzaf+jTUqKoqffvqJRx99lC5dutC4cWMefvhhnnjiCU99BBEREZFKc/nulkuWLGHixIm8/fbbrF+/nm+++YZ58+bx4osvnvUejxZ0TVkJtiKo1xTqN3dfu85WWrzfOcstS4y62HjujNWp5BYUO/XZIiIi4nkPPvggKSkpFBQUsHr1amJjY0vfW7JkCdOnTy9zfVxcHKtWrSI/P5+kpCSeeuqpMjXKRERERGoKh2aSVaag67PPPssdd9zBqFGjAOjcuTO5ubncd999PP3002X+NbKEr68vvr6+joTmPCX1yFoMBJPJMzE4g5N3uCxxabswmofWITkzl6/WpnFX3xqcSBQREREREREROcmhmWSVKeial5d3RiKs5F8X7Xa7o/G63oVQjwxOS5I5ryYZgNls4u6LjcTYh7/twWqrhn0oIiIiIiIiIuIgh5dbOlrQdfDgwbzzzjvMnDmT5ORkFi5cyLPPPsvgwYOr31T8YxlwcAtgugCSZCdneB3PMOqsOdGNFzWhXoA3qYfzWLgl3anPFhERERERERHxBIeWW4LjBV2feeYZTCYTzzzzDPv27aNhw4YMHjyYl156yXmfwllKllpGxkBAiEdDqTL/+uAfAicOw5FkiOjsvEf7WLg9thmTf93F+8uTubJTpNOeLSIiIiIiIiLiCSZ7tVzzWFZOTg7BwcFkZ2cTFBTkuobmPAAbv4C+j8DlHtpd05nej4e9v8PNn0CH65z66IM5+fT992KKrHbm/L0P3ZrWd+rzRUREqspt4wepEvWTiIiIOMpV4weX725ZY9jtp2aStRzo0VCcpqQuWZZz65IBhAX5cW1MYwDeX+HcHTRFRERERERERNxNSbISh7bDsQPg5QdRvT0djXO4aIfLEqP6GXXPftx0gLTDeS5pQ0RERERERETEHZQkK1Eyi6xpHHj7eTQUpwlpaXw97JqZXu0jg7i4VSg2O0xfucclbYiIiIiIiIiIuIOSZCV2/2p8rem7Wp6udCaZ85dblrjn5GyyL9akciS30GXtiIiIiIiIiIi4kpJkANYi2LPCOL5Q6pEBhBgJLI4dgMJclzQxoE1DOjYKIq/Qyoe/qTaZiIiIiIiIiNRMSpIB7F0LhcchoAGEd/Z0NM4TEAJ+9YzjI3tc0oTJZOKhS1sDMP23PWTnFbmkHRERERERERERV1KSDE7VI2veH8wX2B9Jg5K6ZK4p3g9wRYdw2oYHcqygmI9WajaZiIiIiIiIiNQ8F1hGqJIuxHpkJUrqkmW5ri6Z2WzioctaAfDhimSO5Ws2mYiIiIiIiIjULEqS5ecYyy3hwqpHVqK0eL/rZpIBXNUpklZhdcnJL+aThBSXtiUiIiJlpaWlsXfv3tLv16xZwyOPPMJ7773nwahEREREahYlyfasALvVSCbVa+rpaJzPTUkyi9nEgwON2WTvL99NbkGxS9sTERGRU4YPH86vvxoz49PT07n88stZs2YNTz/9NC+88IKHoxMRERGpGZQkqxMKnW6AjkM9HYlrhJTUJHN9rbC/dYmkeWgdjuQV8dkqzSYTERFxl82bN9OrVy8AvvzySzp16sTKlSv5/PPPmT59umeDExEREakhlCSL6gU3fgiXPevpSFyjZCZZzl4oOuHSprwsZv4+wEjKTVu+mxOFVpe2JyIiIoaioiJ8fX0B+OWXX7j22msBaNeuHQcOHPBkaCIiIiI1hpJkF7qAEPANNo6P7HF5c0O6NSYqxJ/M44XMWJPq8vZEREQEOnbsyNSpU1m+fDkLFy7kyiuvBGD//v00aNDAw9GJiIiI1AxKkl3oTCYIaW4cu7guGYC3xcyYAUZtsneXJpFfpNlkIiIirvbvf/+bd999lwEDBnDrrbcSExMDwHfffVe6DFNEREREzs3L0wGIGzRoCQcS3ZIkAxh6URPeWryLfUdP8OXaNEbERbulXRERkdpqwIABZGZmkpOTQ/369UvP33fffQQEBHgwMhEREZGaQzPJaoOSumRZSW5pzsfLzAMna5O9sySJgmLNJhMREXGlEydOUFBQUJogS0lJ4Y033mD79u2EhYV5ODoRERGRmkFJstqgJEnmpplkADd1b0J4kC8HsvOZvW6v29oVERGpja677jo++eQTAI4ePUpsbCyvvfYaQ4YM4Z133vFwdCIiIiI1g5JktUFpkizZbU36eVt4oL8xm+ztX5Mostrc1raIiEhts379evr16wfA7NmzCQ8PJyUlhU8++YQ333zTw9GJiIiI1AxKktUGIUayiuw0KC5wW7O39mpKaF1f9h09wZz1+9zWroiISG2Tl5dHYGAgAD///DNDhw7FbDbTu3dvUlJSPBydiIiISM2gJFltUCcUfAIBOxzZ47Zm/bwt3H+JMYttypJdFGs2mYiIiEu0atWKuXPnkpaWxk8//cQVV1wBwMGDBwkKCvJwdCIiIiI1g5JktYHJBCHNjWM31iUDuK13U0Lq+JCSlcd3G/e7tW0REZHaYvz48Tz22GNER0fTq1cv4uLiAGNWWbdu3TwcnYiIiEjNoCRZbdHg5JJLNyfJAny8GNXPSNBNXrwLq83u1vZFRERqgxtvvJHU1FTWrl3LTz/9VHr+sssu47///a8HIxMRERGpOZQkqy08sMNliRFx0dQL8GZ3Zi7zNh1we/siIiK1QUREBN26dWP//v3s3WvsLN2rVy/atWvn4chEREREagYlyWqLkiRZVpLbm67r68U9fUtmk+3EptlkIiIiTmWz2XjhhRcIDg6mWbNmNGvWjHr16vHiiy9is6kmqIiIiEhFKElWW3hwJhnAnX2jCfTzYkfGcX76M90jMYiIiFyonn76aSZPnszLL7/Mhg0b2LBhAxMnTuStt97i2Wef9XR4IiIiIjWCkmS1RcjJmmTZaVBc6Pbmg/y8GXlyNtn/Fmk2mYiIiDN9/PHHvP/++4wePZouXbrQpUsX/v73vzNt2jSmT5/u6fBEREREagQlyWqLumHgXQfsNjia4pEQ7u4bTR0fC9vSj/HL1gyPxCAiInIhOnz4cLm1x9q1a8fhw4c9EJGIiIhIzaMkWW1hMnl8yWW9AB/u7BMNwFuLd2G3u3422cGcfJ6as4nZ6/a6vC0RERFPiYmJYfLkyWecnzx5Ml26dPFARCIiIiI1j5enAxA3CmkOGZs8liQDGNWvBdNX7mHTvmyWbD/EwHZhLmtrXcphRn+2noPHCpi9di8D2zakQV1fl7UnIiLiKa+88grXXHMNv/zyC3FxcQAkJCSQlpbG/PnzPRydiIiISM2gmWS1SYOTdck8mCQLqePD7b2bAUZtMlfMJrPb7Xy2KoVb3lvFwWMFABRabXy5VrPJRETkwtS/f3927NjB9ddfz9GjRzl69ChDhw7lzz//5NNPP/V0eCIiIiI1gpJktUnJcsusJI+GcW+/Fvh6mUlMO8qKXZlOfXZ+kZUnvv6DZ+Zupshq55rOkTw3uAMAn69OwaoNA0RE5ALVqFEjXnrpJb7++mu+/vpr/vWvf3HkyBE++OADT4cmIiIiUiMoSVabeLgmWYmGgb4Mj20KwJtOnE22/+gJhr2bwJdr92I2wbir2jF5eDeG9WxKsL83e4+cYOmOg05pS0REREREREQuLEqS1SYlSbKjqWAt8mgoD/RviY+Xmd/3HGHV7qrvupWQlMXgt1awcW829QK8+fjuXtzfvyUmkwl/Hws3dW8CwKcJntnZU0RERERERESqNyXJapPASPDyB7vVSJR5UHiQH7f0jAKM2WSVZbfb+WBFMrd/sJqs3EI6RAbx/YMX0691wzLX3XayDtqSHYdIO5xX+cBFRERERERE5IKk3S1rE5PJmE128E9jyWVJIX8PeaB/S75Yk0rC7ix+33OYntEhDt1/otDKk9/8wbeJ+wG4vltjJl7fGX8fyxnXNg+tQ7/WoSzfmcnnq1N58qp2TvkMIiIinjR06NBzvn/06FH3BCIiIiJyAdBMstompLnx1cN1yQAa1fPnxu6Vm02WdjiPG95ZybeJ+7GYTTw3uAOv3xxTboKsxB0nZ5N9uTaN/CJr5QMXERGpJoKDg8/5atasGSNGjPB0mCIiIiI1gmaS1TbVpHh/ib8PaMmXa9NYvjOTDalH6Na0/nnvWbbjEP+YuYGjeUWE1vVh8vCL6N2iwXnvu7RdGJHBfhzIzufHzQe4vlsTZ3wEERERj/noo488HYKIiIjIBUMzyWqbkiWW1SRJFhUSwNBujQF4a/Guc15rt9t5e8ku7vpoDUfzioiJqsf3D11coQQZgJfFzPBexq6aKuAvIiIiIiIiIqdTkqy2adDa+LpvPViLPRvLSWMGtsJsgsXbDrJpb3a51xwvKGbMjPW8smA7Njvc0jOKL+/vTWSwv0NtDesVhZfZxPrUo2zeV35bIiIiIiIiIlL7VCpJNmXKFKKjo/Hz8yM2NpY1a9ac8/qjR48yZswYIiMj8fX1pU2bNsyfP79SAUsVRfWCgFDIy4Tdv3o6GgCiQ+twXVdjNtmbi8+sTbb70HGun/Ib8zel420xMfH6zrx8Qxd8vc5ef+xswgL9uLJTBACfr9ZsMhERERERERExOJwkmzVrFmPHjmXChAmsX7+emJgYBg0axMGDB8u9vrCwkMsvv5w9e/Ywe/Zstm/fzrRp02jcuHGVg5dKsHhDpxuM4z9meTaW04wZ2AqTCRZuyWDL/pzS84u2ZnDd5N/YefA44UG+zLwvjuGxTavUVkkB/7kb9pOTX1SlZ4mIiIiIiIjIhcHhJNnrr7/Ovffey8iRI+nQoQNTp04lICCADz/8sNzrP/zwQw4fPszcuXPp27cv0dHR9O/fn5iYmCoHL5XUZZjxdesPUHDMs7Gc1CqsLtd0jgRg8q87sdns/HfhDu75eC3HCorpGV2f7x+6mO7Nzl/Y/3x6NQ+hTXhdThRZ+Wbd3io/T0RERERERERqPoeSZIWFhaxbt474+PhTDzCbiY+PJyEhodx7vvvuO+Li4hgzZgzh4eF06tSJiRMnYrVaz9pOQUEBOTk5ZV7iRI0vgpCWUHzCSJRVEw9datRL+3FzOsPfX8X/FhlLL++Ma8bno3oTFujnlHZMJlPpbLJPV6Vgt9ud8lwRERERERERqbkcSpJlZmZitVoJDw8vcz48PJz09PRy79m9ezezZ8/GarUyf/58nn32WV577TX+9a9/nbWdSZMmERwcXPqKiopyJEw5H5MJYm4xjqvRksu2EYFc1SkCux1W7T6Mj5eZV2+K4fnrOuHj5dw9JoZ0a0yAj4WkQ7kk7M5y6rNFREREREREpOZx+e6WNpuNsLAw3nvvPbp3786wYcN4+umnmTp16lnvGTduHNnZ2aWvtLQ0V4dZ+3S+yfiavBRyDng2ltP847LWBPhYaBTsx9cP9OHG7k1c0k6gnzfXdzPq4n22SgX8RURERERERGo7L0cuDg0NxWKxkJGRUeZ8RkYGERER5d4TGRmJt7c3FsupnQjbt29Peno6hYWF+Pj4nHGPr68vvr6+joQmjgppDlG9IW0VbJ4NfR7ydEQAtI8MYvnjAwny98bb4toc7u29m/H56lR++jODjJx8woOcs5xTRERERERERGoeh7IQPj4+dO/enUWLFpWes9lsLFq0iLi4uHLv6du3L7t27cJms5We27FjB5GRkeUmyMSNutxsfK1GSy4BGtT1dXmCDIyEXM/o+lhtdr5Yk+ry9kRERGqCKVOmEB0djZ+fH7GxsaxZs6ZC982cOROTycSQIUNcG6CIiIiIiziciRg7dizTpk3j448/ZuvWrYwePZrc3FxGjhwJwIgRIxg3blzp9aNHj+bw4cM8/PDD7Nixg3nz5jFx4kTGjBnjvE8hldPxejB7Q/omyNji6Wg84vaTBfy/WJNKkdV2nqtFREQubLNmzWLs2LFMmDCB9evXExMTw6BBgzh48OA579uzZw+PPfYY/fr1c1OkIiIiIs7ncJJs2LBhvPrqq4wfP56uXbuSmJjIggULSov5p6amcuDAqRpXUVFR/PTTT/z+++906dKFf/zjHzz88MM8+eSTzvsUUjkBIdBmkHFczWaTucuVnSIIretDRk4Bi7ZmnP8GERGRC9jrr7/Ovffey8iRI+nQoQNTp04lICCADz/88Kz3WK1WbrvtNp5//nlatGjhxmhFREREnMuhmmQlHnzwQR588MFy31uyZMkZ5+Li4li1alVlmhJX63IzbPsBNn0Fl00As+uXOVYnvl4WhvWMYsqvSXy6KoUrO0V6OiQRERGPKCwsZN26dWVWBJjNZuLj40lISDjrfS+88AJhYWHcc889LF++/LztFBQUUFBQUPp9Tk5O1QIXERERcZLalRGRM7UeBL7BkLMPUlZ4OhqPuLVXU0wm+G1XFrsOHvd0OCIiIh6RmZmJ1WotXR1QIjw8nPT09HLvWbFiBR988AHTpk2rcDuTJk0iODi49BUVFVWluEVEREScRUmy2s7bDzoOMY5r6ZLLJvUDuKxdGACfr07xcDQiIiI1w7Fjx7jjjjuYNm0aoaGhFb5v3LhxZGdnl77S0tJcGKWIiIhIxSlJJtBlmPF1y3dQdMKzsXhISQH/2ev2kldY7OFoRERE3C80NBSLxUJGRtkanRkZGURERJxxfVJSEnv27GHw4MF4eXnh5eXFJ598wnfffYeXlxdJSUnltuPr60tQUFCZl4iIiEh1oCSZQNM4CI6CghzY/qOno/GIS1o3pGlIAMfyi/kucb+nwxEREXE7Hx8funfvzqJFi0rP2Ww2Fi1aRFxc3BnXt2vXjk2bNpGYmFj6uvbaaxk4cCCJiYlaRikiIiI1jpJkYhTr73KzcfzHl56NxUPMZhO3924KwKerUrDb7R6OSERExP3Gjh3LtGnT+Pjjj9m6dSujR48mNzeXkSNHAjBixIjSwv5+fn506tSpzKtevXoEBgbSqVMnfHx8PPlRRERERBymJJkYOp9Mku1aCLlZno3FQ27qHoWPl5k/9+eQmHbU0+GIiIi43bBhw3j11VcZP348Xbt2JTExkQULFpQW809NTeXAgQMejlJERETENUz2GjBlJicnh+DgYLKzs1W3wpXevQQObISrX4Ve93o6Go/455cb+Xr9XoZe1JjXb+7q6XBERKQKNH6oGdRPIiIi4ihXjR80k0xO6XKL8bWW7nIJcEecUcD/hz8OcDi30DWN2GxwNBV2LoSVk+H7h2HjTNe0JSIiIiIiIiIV4uXpAKQa6XQD/Pw07P0dspKgQUtPR+R2MU2C6dQ4iM37cvhqbRr396/Cn4G1GI4kw6HtcGgbZO44+XUnFOWVvXbddLAWwkUjqhS/iIiIiIiIiFSOkmRySmA4tLwUdv1iFPAfOM7TEbmdyWTijt7NeOLrTXy+OpV7+7XAbDad+6aifMjaVTYRdmiHcc5WVP49Zm9o0AoatgW7FbZ+b8wo868P7Qc7/4OJiIiIiIiIyDkpSSZldRl2Mkk2CwY8CabzJIguQNfGNOZf87aSejiPZTsPMaBt2Kk37XZjmWTKCiMRdmgbHE0Bu638h3kHQGgbIxnWsC2EtoWG7aB+NFi8Tj3zu4dgw6cw+x64fTY0v8Tln1NERERERERETlGSTMpqdw141zGWCe79HaJ6eToit/P3sXBT9yg+/C2Zz1alnEqS2e3wywT47X9n3uRX78xEWMM2ENQEzOcp/Wcywd/egBNHYNsP8MVwuOsHaNTVyZ9MRERERERERM5GSTIpy6eOsdzvj5nGbLJamCQDuK13Uz78LZlF2w6SdjiPqHp+MP+fsPZD44Kut0GjbicTY+2gTsOqzbqzeMENH8DnN8Ke5fDZDXD3TxDayjkfSERERERERETOSbtbypm63Gx83fwNFLtoh8dqrmXDulzcKhS7HWat2g1z7j+ZIDPB4P/BkLeh173Gssi6Yc5ZlurtB7fMgMgYyMuET4dAzv6qP1dEREREREREzktJMjlT8/5QNxxOHDbqk9VSt/duhi+F9FjzCGz6EsxecMP70P0u1zXqFwS3fW0U9c9Og0+vh7zDrmtPRERERERERAAlyaQ8Fi/ofJNx/Mcsz8biQfEt6/Cp/+sM4HesZh8Y9jl0vtH1DddtCHfMgcBGxsYAM26GwlzXtysiIiIiIiJSiylJJuUrWXK5/UfIz/ZsLJ5w4ihenw+ll/0Pjtv9eCH4BWh7pfvar9cU7vjG2BBg7+8w645au/RVRERERERExB2UJJPyRXQxCtJbC2DLt56Oxr2OH4Lpf4O9a7D51uPO4qf5+EBTth7IcW8cYe3httngHQBJi2DuA2CzuTcGERERERERkVpCSTIpn8kEXYYZx3986dlY3Cl7L3x0FWRsgjphmEfOI6LDxQB8tirF/fFE9YRhn4LZGzZ/DT8+Dna7++MQERERERERucApSSZnV1KXbM9yOJrm2VjcISsJPrwKsnZCUBMY+SNEdOL23s0AmLNhH8fyi9wfV6t4uH4qYILfp8GSl90fg4iIiIiIiMgFTkkyObt6UdDMmEXFpq88G4urZWwxZpBlp0JIS7h7AYS2AqB3ixBahdUlr9DKnA37PBNf5xvh6v8Yx0tfhtXveiYOERERERERkQuUkmRybjElSy5nXbjL/Patg+lXw/EMCO9kJMjqRZW+bTKZuOPkbLJPE1Kwe+rPode9MOAp4/jHx+GPCzxxKSIiIiIiIuJGSpLJubW/Fiy+cGgbpP/h6Wicb88K+PhaOHEEGveAu36AumFnXHb9RY3x97aw8+BxVicf9kCgJ/V/HHrdZxzPfQB2LvRcLCIiIiIiIiIXECXJ5Nz860Hbq4zjC62A/46f4bMboPA4RPeDEXPBv365lwb5eTOkW2PAQwX8S5hMcOW/odONYCuGWXdA6mrPxSMiIiIiIiJygVCSTM6vZJfLTV+BzerZWJzlzzkw81Yozoc2V8Fts8E38Jy33N67KQALNqdz8Fi+O6Isn9kMQ94xCvoXn4AZNxk11URERERERESk0pQkk/NrFQ/+IUbNrt1LPB1N1a3/FGbfbczE6nQjDPsUvP3Oe1vHRsF0b1afYpudWWs8vNunlw/c/Ak06QX52fDp9XBkj2djEhEREREREanBlCST8/PygU5DjeOavuRy1Tvw3YNgt8FFd8LQ98DiXeHbSwr4f/BbMilZua6KsmJ86sDwWdCwPRxPNxJlxw96NiYRERERERGRGkpJMqmYkiWXW7+HQg8nhyrDboelr8CCJ43v4x6Ewf8Ds8Whx1zdOZIuTYI5mlfEPR+vJftEkQuCdUBACNzxDdRrCod3GzXW8rM9G5OIiIiIiIhIDaQkmVRMk55QvzkU5cK2eZ6OxjF2Oyx8Fn59yfh+4NNwxb+MIvgO8vEyM21EDyKC/Nh18DgPzlhPsdXm5IAdFNQI7pgLdRoaO5B+MRyKPFgzTURERERERKQGUpJMKsZkOjWb7I9Zno2loopOwJ7fYM4DsPIt49yVL0P/xyuVICsRHuTH+3f2wN/bwvKdmbzwQzUomt+gJdz+NfgGQcoK+OQ6SFpsJAhFRERERERE5LyUJJOK63Kz8TVpcfWsfXX8kLEc9Ken4f14mBQF06+GP2aCyQzXTobeo53SVKfGwfx3WFcAPklI4ZOEPU55bpVExsCtX4CXH6StMmqUTb0YEr+A4kJPRyciIiIiIiJSrXl5OgCpQRq0hMY9YN9a2DQb4v7uuVjsdsjcCakJkLYaUlfB4aQzr6sbAU1jjSL9rS5zaghXdorg8Svb8sqC7Tz//RaaNahD/zYNndqGo3Ije/Nxxxlcnj2b1vu+hYzNMPcBWPQ8xN4P3e8C//oejVFERERERESkOjLZ7dV/PVZOTg7BwcFkZ2cTFBTk6XBqtzXTYP5jENkV7l/qvnaLC2D/BiMZlrrKSIydOPyXi0wQ1h6iYqFpb+NVr1mVllaej91u57Gv/uDr9XsJ9PXim7/3oXV4oMvaO5es4wXcPf13Nu7NxmSCH0Z1ouP+r2H1u8bulwDedeCiO4wZdfWjPRKnXMAK82DdR2D2hp6jwKzJyuJZGj/UDOonERERcZSrxg9KkoljcjPhtbZgK4Yxa6BhWxe1k2UkwtJWQepq2L8erH9ZMujlB427G8mwqN4Q1dMjs6QKiq3c8f4a1uw5TNOQAOaO6UtIHR+3xpB2OI87P1zD7sxTO4/2aFafrx6Iw2Qtgs2zYeVkOPin8abJDO2vhT4PQZMebo1VLkA2K2z8Ahb/C44dMM61vgKGvqeZi3Jum2bD7iVw7Vsu+QcNjR9qBvWTiIiIOEpJMg2eqo8Zw2DHAuj3T7hsvPOeW5gLG2fC2o8gY9OZ79dpeNossTiI6AJe7k1Gnc3h3EKum7KCtMMn6BUdwqejeuHrZXFL21sP5HDnh2s4eKyAxvX8eeXGLoz6eC0niqy8eWs3ro1pZFxotxv15BImG19LNI2DuAeh7VVgdnHMdjvk7Ae/IPD1zIw7cbJdi2DheGNpL0BwlJFMLz5hzFYc9jlEdPJoiFINFeXDT+Ng7YfG9zd/Ah2uc3ozGj/UDOonERERcZSSZBo8VR+bv4HZIyG4KTy8sepLqrL3Gss4102H/KOnzoe2OTVLrGlvCGnh0qWTVbUz4xhD317JsYJibrioCa/e1AWTi+NdvTuLUZ+s5Vh+MW3DA/n47l5EBPvx1qKdvLZwB5HBfiz6Z38CfP5SfjB9MyRMgU1fga3IOBfS0qgzFzMcfAKqFpjNBkdT4NB2OLTt1NfMHVB43FiO1/JS6HAttL0aAkKq1p64X/pmWPjsqYSrXzBc8n/Q6z6jv2fdBkdTwcvfmCXU5SbPxivVR1YSfHnnyX8MMcElj0H/J8Hi/DKpGj/UDOonERERcZSSZBo8VR9FJ+DVNlCQA3fNh+i+jj/Dboe9v8Oqt2HLd2C3GufrR0PsA9D5ZqjTwKlhu8PSHYcY+dEabHZ44sp2jB7Q0mVt/fRnOg99sYHCYhs9o+vz/oieBAd4A5BfZCX+9aXsPXKCf1zWmrGXtyn/ITkHYM17sPYDyM82zvmHGPWket0LdcPOHYTNCkf2nEyEnUyGHdxqbKpQfKL8e0yWU/0NYPaC5pcYs0ja/Q3qhDr2ByHulbMfFr8EiZ8DdiPh2es+I9FxerIz7zB8PQqSFhnf9/47XP4CWLw9ErZUE5u/hu/+YSTLA0KNJblO3lTldBo/1AzqJxEREXGUkmQaPFUv346BDZ8Zu0Ze+2bF77MWwZZvjeTYvnWnzkf3M36JbjPI9Uv+XOzjlXuY8N2fmEww9fbuDOoY4fQ2vliTytNzNmGzQ3z7cCYP74afd9k/tx83HWD05+vx9TKz6J/9aVL/HLPDCo4bSY+EKcYMMACLL3S52ViK2aAlHE4+LRl2MiGWuROsBeU/0+JjzAZs2BYatjv1CmluzCTZ+p3x30LJMj0waqU162skzNoPhkDn/9lJJRUcg9/+Z9S2K0mAdrzeWHId0qL8e2xW+HUiLH/V+L7ZxXDTR+dPvsqF56/LK5v1hRs+gKBIlzar8UPNoH4SERERRylJpsFT9ZK8DD4eDL7B8NgO8PY79/W5Wcaud7+/f6qwt8UXOt8EvR+AiM6uj9mNnp27mU9XpeDvbeGrB+Lo1DjYKc+12+1MXryL1xbuAGBYjyheur4TXpYzl7za7XZunbaKVbsPc03nSKbcdtH5G7BZYev3Rt2yvb+fOm/2PrUs86+8/KFhm5NJsNMSYvWaVWz5VFaSkSzb8i0cSDztDZNRL63DtUbCLLjJ+Z8lzmcthvUfw5JJkHvIOBfVG674l7FZRkVs/QHmPACFxyCwkVF/qqL3Ss2XlQRf3QnpJ5dX9vsnDBjnkuWVf6XxQ82gfhIRERFHVask2ZQpU/jPf/5Deno6MTExvPXWW/Tq1eu8982cOZNbb72V6667jrlz51a4PQ2eqiGbDd7oBDn7zl1w+eBWWPUO/DELivONc3XDjeV83UdC3Ybui9mNiq02Rk7/neU7M4kI8uPbB/sSHnSeROJ5WG12nv/+Tz5JMGZ6PTiwFf+8os05655tPZDDNW8ux2aHL+7tTVxLB5awpq6GhLeMBAd28K5zWhLstK/1mlW9Ll2JI3uMJN2Wb8sm6QCa9Dw5w+xaqN/MOe3J2dntxgYdC8cbteTAqFt3+fPGslhH6+1l7oSZt0HmdiPpevUrxt8B1bjOoDjB5q/hu4eNBGlAg5PLK+Pd1rzGDzWD+klEREQcVW2SZLNmzWLEiBFMnTqV2NhY3njjDb766iu2b99OWNjZl9Ds2bOHiy++mBYtWhASEqIk2YVg4QT47Q3jF+ZbPj913maDXb8YSyp3/3rqfGSMsaSy4/Xg5ev2cN0t+0QRQ9/+jaRDuXRpEsys++Lw96ncUtKCYitjv9zIvD8OYDLBhL914K6+zSt07zNzN/HZqlTaRQQy7x/9sJgdTEocyzCWVAY1cV4yrCKy955KmKWuAk77qyqyq5Ew63CdsRRUnGv/Bvj5Wdiz3PjeP8SY+dNjZNVqihUcg7l/N5baAnS7A65+9fwzUaXmKcqHn54y6h3CyeWV70NQI7eGofFDzaB+EhEREUdVmyRZbGwsPXv2ZPLkyQDYbDaioqJ46KGHePLJJ8u9x2q1cskll3D33XezfPlyjh49qiTZhSBjC7wTZ8wKeWyHUYNq4xeweipk7TKuMZmNJFrvvxs7VNayWSMpWbkMmfIbR/KKuKZzJG/d2g2zg0mqY/lF3P/pOlYmZeFtMfHazV25Nqbiv2geyS1kwKtLyD5RxL+GdOL23jVwFtax9FMJs5TfwG479V54Z+g9Grrd5rn4zmX7AijKhTZXgk8dT0dzbkdSYPGLxq6nYCyJjvs7XPyosXulM9jtRnJ90QtGPzbqBjd/CvWinPN88bwyyyuBfo+5bXnlX2n8UDOon0RERMRRrho/ODRiLSwsZN26dYwbN670nNlsJj4+noSEhLPe98ILLxAWFsY999zD8uXLz9tOQUEBBQWnioHn5OQ4Eqa4S3gHI0GRscn4hWj/Rig4uUOibzB0HwE9763VS+OaNajD1Nu7c/sHq5m36QAtG9Zh7BVtK3z/oWMFjJy+hs37cqjjY+HdO3pwcWvHdn+sX8eHR+Nb89z3W3jt5+0M7tKodBfMGiMwwthts9e9cPwQbPvBSJglLzP++/v270ZCtuutno60rA2fGZtcAPjUNZaKxtxibFThzll553PiKCx/DVa/e2ojhi63wKXPOD95ZTIZSbfIGJh9tzFr7b3+cONH0KK/c9sS9/Pw8koRERERkapw6Le0zMxMrFYr4eHhZc6Hh4eTnp5e7j0rVqzggw8+YNq0aRVuZ9KkSQQHB5e+oqI0w6DaihlmfE1eZiTIGrQylk+N3WIU9q7FCbISsS0aMPF6Y2OCNxfvYu6GfRW6LzUrjxunrmTzvhwa1PHhi/t6O5wgK3Fb72a0DqvLkbwi/vvLjko9o9qo29BY9jdiLvzfLoh9wDj/3UOQfP4kvNvsXgLfP2wcBzSAwuOwcQZ8ci280Rl+ec7YIdRTbDY4sBGW/Qfe7Aor3zQSZM0vgfuWwtB3XTu7q+WlRjuRMZCXBZ8Ogd/eNGaaSc1TlA8/jDUSn4XHjOWVD6xQgkxEREREahSXTmU4duwYd9xxB9OmTSM0tOK/3I8bN47s7OzSV1pamgujlCrpehs06QUtL4PhX8GY343ZPr51PR1ZtXJTjyju798CgMe//oN1KUfOef2f+7MZ+s5KUrLyaFLfn9mj+9ClSb1Kt+9tMTNhcEcAPl2Vws6MY5V+VrUSEAKDJhl17mxFMOs2OFQNkoAHt8KsO8BWDJ1uhMd2wd0/Qfe7jGWLOXthxX9hSi94b4Axgys30/VxZe+F9Z8aiYxXW8O7l8Dif8GJI8ZGDMO/ghHfQaOuro8FjCT63T9BzHBj6eXCZ2H2SCg47p72xTmykuCD+FP1x/o9Zvx35Ob6YyIiIiIiVeVQTbLCwkICAgKYPXs2Q4YMKT1/5513cvToUb799tsy1ycmJtKtWzcsllPFym02o5aQ2Wxm+/bttGx5/qLbqlUhFwKbzc79n61j4ZYMQuv6MHdMX5rUDzjjupVJmdz3yTqOFxTTLiKQT+7uRVgVd8Ysce8na1m4JYN+rUP55O5e59wZs0YpOgEfXwt710D9aBi1COpUbtZdlR3LgPcvg+w0aBoHI74tu1FFUb6xa+TGmbBroZFIAzB7QavLjeWYba50TjH7/BzYs8LYQCPpV8jaWfZ9n7oQfTG0H2wsr/RAzSjAmD32+/uw4Enjz6Nhexj2GYS28kw8UnGbv4Hv/lFtl1dq/FAzqJ9ERETEUdWqcH+vXr146623ACPp1bRpUx588MEzCvfn5+eza9euMueeeeYZjh07xv/+9z/atGmDj4/PedvU4EkuFLkFxdw0NYEtB3JoGx7I7NFxBPqdqg82f9MBHpmZSKHVRmzzEKbd2YMgP+fVD0vJyuXy15dRaLUxbUQPLu8Qfv6baorcTCM5dWSPMbvxzu/A29+9MRTmwvRrjDpbIS1h1C/GbLezyc00ajht/MK4p4RfsDE7LuZWiIqt+IYX1mLYt+5UUmzv72C3nnrfZIbG3aHFQGg5EBr3AK/z/x3sNqmr4csRcDwdfIPg+neh3dWejkrKU5QPPz9tJDcBmvaBGz+odrPHNH6oGdRPIiIi4qhqkySbNWsWd955J++++y69evXijTfe4Msvv2Tbtm2Eh4czYsQIGjduzKRJk8q9/6677tLullKrHcg+wbWTf+PQsQIubRfGtBE9sJhNfLoqhfHfbsZuhys7RvDGLV3x87ac/4EO+veCbbyzJIlmDQL4+dFL8PVyfhsec2iHsewrP9tIMt3wofsK5NusMOt22D7fmFFzz0JocP6ZsqUObTdml/0xC3JOq1tXv7kxu6zLzRDSouw9drux1K0kKbZnORT8ZaOTkBankmLR/cC/XqU/olscS4ev7oLUk5vB9H8C+j9ZvTY6qO2ykow+Sv/D+L7fP2HAU56biXgOGj/UDOonERERcVS12N0SYNiwYRw6dIjx48eTnp5O165dWbBgQWkx/9TUVMz6ZUbkrCKD/Xl/RA9ufjeBxdsO8tK8rdT18+LNRcZSuOGxTXnxuk5YzK5ZCjlmYCu+XreXlKw8Plyxh9EDHEjkVHcN28Cwz+HT6+HPOUaCKX6Ce9r+6WkjQWbxhVu+cCxBBtCwrRHrpc8aya6NM2Hrd3AkGZZMMl5RvY2EmV+QkRTbvcRY1nk6//rQvL+RFGsxsOZtnhEYYdSz+vkZWPMuLP230ZdBjYzZZX5Bxu65fkHGjLvSc6d/PXneFbPk7HZjSai18OSr2NjwwFoIxYWnnS/8y7kCsBZBccFfrinnnH+IsQw2KhZ8zlyS7RElCdldC2HxS6eWV17/HrSuPssrRURERESqwuGZZJ6gf2GUC9EPf+znwRkbypx7+LLWPBLf2uW1wr5et5d/frWROj4Wfn1sgNNqnlUbiTNg7mjj+Nq34KIRrm1v9bvw4+PG8Y0fQaehznluYS5sm2csx9y9xChu/1cWHyOZUpIUi4wB8wUyO3DjTGOH0OL8yt3v5Vd+Es3icypBdXqyquSrregc7xc69zOei8UHmvQ0dhxtfol7l8fa7UaCNnm5kbTdswKOHTj1ftM4uOEDCG7snngqSeOHmkH9JCIiIo6qNsstPUGDJ7lQvbloJ68v3IHJBC9c14k7ertn1o/NZmfoOytJTDvKDRc14bWbY9zSrlv9OtGYhWT2gttmG0kkV9g239hV026D+Ofg4kdd007OAdj0lVHDzGaFFv2NpFizOPCp45o2q4PsfXBgo7GMND8HCrJPfs05+9dCN++OafYyZhB6+RiJLYsvWLyNDRss3ie/9yn/XOk9p72OpkDysrLLbgG8/KFp75NJs/5GQtSZSxyP7DGSYSWJsb+2b/Ex6v21uxp63V8tl1f+lcYPNYP6SURERBylJJkGT3IBstvtzE3cR+N6AfRqfo4C7y6wIfUI17+9EoC5Y/rSNaqeW9t3ObsdvrnXSCz5BsE9P0NYe+e2sX8DfHQ1FOXBRXfC4P9VvMi+uI7Neu4kmrXwL4kp79OOvc5y/rRj81+ucUWf2+1weLeRLCt55WWWvcY3CJr1OTXTLKyjY7XbjqadmiWWvByyU8u+b/aGJj2MWnbN+xmz2ty9GUYVafxQM6ifRERExFFKkmnwJOJ0//xyI1+v30vXqHp8M7oPZhfVQfOY4gL45DqjCHxwU7h3EdQNc86zj6bC+/FwPANaXgrDvzQSJiKuYLfDoW2nEmZ7lhsbVJyupJZZyUyz0NZlE3g5+0/OEltmJMaO7Cl7v9nL2P00+mIjMVadaqJVksYPNYP6SURERBylJJkGTyJOdzAnn4GvLiG30MrrN8cw9KImng7J+fIOG8msw0lGAuDOH6r+i39+NnwwCA5tNWbv3L3AqHcl4i42K6RvOpUwS1l55jLTuhHGDDDvAOOaw7vLvm+yQKNuJxNr/YyNIXzruu8zuIHGDzWD+klEREQcpSSZBk8iLvHOkiT+vWAbYYG+LH5sAHV9q3+dIYdlJcH7l8GJI9B+MNz0iWPL0k5nLYLPbzQK6QdGwqhfIPgCTC5KzWItMpb/Ji81ZoulrT5zwwOT2ahjFt3PeDXtfcEndzV+qBnUTyIiIuIoV40fLsDfhkXEEXdfHM3M31NJycrj7V938fiV7TwdkvM1aAm3zDCWXm79Hn6ZAFe86Phz7Hb44REjQeZdB4bPUoJMqgeLN0T1Ml6X/B8U5cPe340ZZEUnjNplTePAv56nIxURERERqbYqOZVCRC4Uvl4Wnr7aKGj//vJkUrJyPRyRizTrA9e9bRyvfBPWfuj4M5a/Bhs+M2bk3PSRMStHpDry9jOWUA58ykgIt71KCTIRERERkfNQkkxEuLxDOP1ah1JotfHSvK2eDsd1utwEA582juc9Brt+qfi9m2bD4pOzz656BdoMcn58IiLVwJQpU4iOjsbPz4/Y2FjWrFlz1munTZtGv379qF+/PvXr1yc+Pv6c14uIiIhUZ0qSiQgmk4nxf+uAxWzi5y0ZrNiZ6emQXOeS/4OYW8FuhS/vgow/z39PykqYO9o4jnsQet3r0hBFRDxl1qxZjB07lgkTJrB+/XpiYmIYNGgQBw8eLPf6JUuWcOutt/Lrr7+SkJBAVFQUV1xxBfv27XNz5CIiIiJVp8L9IlLque/+ZPrKPbQOq8uPD/fDy3KB5tGLC+GzoUa9pqAmcO8iCIwo/9rMXfBBvFH0v93f4OZPK1/0X0TcSuMHx8XGxtKzZ08mT54MgM1mIyoqioceeognn3zyvPdbrVbq16/P5MmTGTFiRIXaVD+JiIiIo1w1ftBveiJS6tH4NtQP8GbnweN8vjrV0+G4jpcP3PwJNGgNOXthxjAoLKcWW26msZPliSPQuDsMnaYEmYhcsAoLC1m3bh3x8fGl58xmM/Hx8SQkJFToGXl5eRQVFRESEnLWawoKCsjJySnzEhEREakO9NueiJQKDvDmn1e0BeD1hTs4klvo4YhcKCAEbvsSAhrAgUT4+l6wWU+9X5QPM4fDkWSo1xRunQk+AR4LV0TE1TIzM7FarYSHh5c5Hx4eTnp6eoWe8cQTT9CoUaMyiba/mjRpEsHBwaWvqKioKsUtIiIi4ixKkolIGbf2akq7iECyTxTx+sIdng7HtUJawC1fgMUXts+Dn58xzttsMPcBSFsNfsFw22yoG+bZWEVEqrmXX36ZmTNnMmfOHPz8/M563bhx48jOzi59paWluTFKERERkbNTkkxEyrCYTUwY3BGAz1ensPVA9V0Gk5yZy+OzNzLpx63kFRZX7iFNY+H6d4zjVW/D6vdg8Qvw5xwwe8Owz6BhW+cFLSJSTYWGhmKxWMjIyChzPiMjg4iIs9RtPOnVV1/l5Zdf5ueff6ZLly7nvNbX15egoKAyLxEREZHqQEkyETlDXMsGXN05ApsdXvh+C9Vtf4+DOfk8PWcT8a8v5cu1e3l36W6ueXMF61OPVO6BnW6Ay8Ybxz8+Div+axxf+xY0v8Q5QYuIVHM+Pj50796dRYsWlZ6z2WwsWrSIuLi4s973yiuv8OKLL7JgwQJ69OjhjlBFREREXEJJMhEp17ir2uPrZSZhdxYLNlesFo2rHcsv4rWft9P/P0v4fHUqVpudAW0bEhnsR3JmLje+s5LXft5OYbHN8YdfPBa63Q6cTAj2fxK63urU+EVEqruxY8cybdo0Pv74Y7Zu3cro0aPJzc1l5MiRAIwYMYJx48aVXv/vf/+bZ599lg8//JDo6GjS09NJT0/n+PHjnvoIIiIiIpXm5ekARKR6igoJ4P5LWvDm4l08PCuRhVszuL13M7pF1cNkMrk1loJiK5+tSmXy4p0cySsC4KKm9Xjyqvb0ah5C9okinvvuT+Zs2Mdbi3exeNtB/jusK23CAyveiMkEf3sD/EPAv56RNBMRqWWGDRvGoUOHGD9+POnp6XTt2pUFCxaUFvNPTU3FfNouv++88w6FhYXceOONZZ4zYcIEnnvuOXeGLiIiIlJlJnt1W0dVjpycHIKDg8nOzlbdChE3yiss5u7pv7Nq9+HScx0ig7i9dzOu69qIOr6uzbPbbHa+3biP137ewd4jJwBo2bAOj1/Zjis6hJ+RrJu/6QBPz9nEkbwifLzM/N8Vbbn74uZYzO5N6olI9aDxQ82gfhIRERFHuWr8oCSZiJyT3W5n495sPk1I4Yc/9lNwciljoK8X11/UmNt7N3NsxlYF21yy4xCvLNheunFAeJAvj8a34cbuTfCynH2l+MGcfJ78ZhOLtx0EoFfzEF67KYaokACnxigi1Z/GDzWD+klEREQcpSSZBk8iHnc0r5DZ6/by+epUkjNzS8/3ah7C7b2bcWXHCHy8qlbqMDHtKC//uLV09lqgnxejB7RkZJ/m+PtYKvQMu93OrN/TePGHLeQWWqnjY2HC4I7c1KOJ25eKiojnaPxQM6ifRERExFFKkmnwJFJt2Gx2fkvK5LNVKfyy9SBWm/HXSGhdH27uEcWtvZo6PHMr6dBxXv1pOz+e3CTAx8vMXX2i+fuAltQL8KlUnKlZefzzq0R+32PsehnfPoxJQ7vQMNC3Us8TkZpF44eaQf0kIiIijlKSTIMnkWopPTufL9akMvP3VDJyCgCjBv7AtmHc0bsZl7RpeM6aYAdz8nlj0U5m/Z6G1WbHZIIbLmrCo5e3oXE9/yrHZ7XZeX/5bl77eQeFVhshdXyYeH0nruwUWeVni0j1pvFDzaB+EhEREUcpSabBk0i1VmS1sWhrBp+uSuG3XVml55vU92d4bFNu7hFFaN1TM7hy8ot4d2kSH6xIJr/IqHMW3z6M/xvUjrYRzq1xBrAtPYdHZ20srXE2tFtjJlzbkWB/b6e3JSLVg8YPNYP6SURERBylJJkGTyI1xu5Dx/l8dSqz1+0l+0QRAN4WE1d1imR4bFM278tmyq+7OJJnvHdR03o8eVV7ejUPcWlchcU2/rdoB+8sScJmh0bBfvznphj6tgp1absi4hkaP9QM6icRERFxlJJkGjyJ1Dj5RVa+37ifz1alsHFv9hnvt2xYh8evbMcVHcLdWlB/XcoR/vllInuy8gC4q080T1zZrsIbA4hIzaDxQ82gfhIRERFHKUmmwZNIjbZpbzafrUrh2437qOfvwyPxrbmxexO8LFXbDbOy8gqLmTh/K5+tSgWgRcM6/PfmrsRE1fNIPCLifBo/1AzqJxEREXGUkmQaPIlcEGw2O+ZzFPJ3tyXbD/L47D84eKwAi9nEmIGteOjSVnh7KHknIs6j8UPNoH4SERERR7lq/KDfAkXErapTggxgQNswfn70EgbHNMJqs/Pmop1c+toSXvh+C7/tyqSw2ObpEEVERERERMQNvDwdgIiIp9UL8OGtW7txeYdwxn+7mbTDJ/jwt2Q+/C2ZQF8vLmnTkEvbhTGgbUManLZDp4iIiIiIiFw4lCQTETnp2phGXNoujBU7D7Fo60F+3X6QzOOFzNt0gHmbDmAyQbeoelzWPpxL24XRLiLQrRsOiIiIiIiIiOuoJpmIyFnYbHb+2JfN4q0ZLNp2kD/355R5v1GwH5e2D+Oy9uHEtWiAn7d2xxSpTjR+qBnUTyIiIuIoFe7X4ElEPOxA9gl+3XaIxdsyWLErk/yiU/XK/L0t9G0VymXtw7i0XRjhQX4ejFREQOOHmkL9JCIiIo5y1fhByy1FRCooMtif4bFNGR7blPwiKwlJWSzalsHirQfZn53PL1sz+GVrBgCdGgdxabtwLmsXRufGwdVuwwIREREREREpSzPJRESqyG63sy39GIu3HWTR1gw2pB3l9L9Zo0L8GXVxC27uEYW/j5Zkivtk5xWxce9R6vh6EeTnRV0/LwL9vAnwttSKxK3GDzWD+klEREQcpeWWGjyJSA2RebyAJduNZZnLdmRyvKAYgPoB3tzZJ5oRcdGE1PHxcJRyoUs6dJyhb68k+0TRGe+ZTFDX14sgP2/q+noReFoCLdDPi8CSc77GOeM94/ro0DrU9a0ZE9E1fqgZ1E8iIiLiKCXJNHgSkRroRKGV2ev3Mm3ZblIP5wHg521mWI8oRvVrQVRIgIcjlAvRkdxCrn/7N/Zk5RFa1xd/HzPH84s5ll9Msa1q/9sP9vfm81GxdGoc7KRoXUfjh5pB/SQiIiKOUpJMgycRqcGKrTYW/JnOu0t3s2lfNgBmE1zTpRH3X9LCYwmHvUfyyC+y0axBAN4Ws0diEOcqLLZxxwerWZ18mMb1/Jk7pi8NA30BY2lwfpGNYwVFHMsvLk2cHS8oIqfkOL+YY/lFHC8wvs857TjzeAFH84poGOjLnL/3oUn96p3k1fihZlA/iYiIiKOUJNPgSUQuAHa7nYSkLKYu282yHYdKz/drHcr9l7Skb6sGmEyuqxWVfaKIhKQslu88xIpdmaRkGbPbvMwmokPr0DqsLq1Oe7VsWBc/b9VRqynsdjuPz/6Dr9btpa6vF1+P7kPbiECnPT8nv4ibpyawLf0YrcLq8vUDfQgO8Hba851N44eaQf0kIiIijlKSTIMnEbnA/Lk/m/eW7eaHPw5gPbkErmOjIO7v35KrO0Xg5YSZXUVWGxvTjrJ8ZybLdx4iMe0op6+28zKb8PEyk1doLfd+kwmi6geUSZyVvIL8qm9ypLaaujSJl3/chtkEH9zVk4Ftw5zexoHsE1w/ZSXpOfnENg/hk3t64etVPROpGj/UDOonERERcZSSZBo8icgFKu1wHh+sSGbW72mcKDKSVVEh/tzbrwU3dXdsR0y73c6erDxW7DzEsp2ZrErK4tjJjQNKtGxYh36tG9KvdSixLRpQx8fCgex8dh48zq6Dx9l18Bi7Dh5n58HjHM07s+h7ifAgX1qF1aV1WCAtw+qWzkJrUMfHpbPhpHwLNqcz+vN12O3w3OAO3NW3ucva2nogh5umJnC8oJhrYxrxxrCu1XK3TI0fagb1k4iIiDiqWiXJpkyZwn/+8x/S09OJiYnhrbfeolevXuVeO23aND755BM2b94MQPfu3Zk4ceJZry+PBk8iUhscyS3kk4QUPk7Yw+HcQqBiO2IezStkZVJW6WyxvUdOlHm/foA3fVuFcknrhlzcOpRG9fwrFI/dbicrt7A0YZZ0Mom28+AxMnIKznqfj5eZAB8LAd4W/H0s1PH1wt/bYpzz8Tr51YK/jxd1fIxrTj8f4ON18pyFOj5ehAX5asnneWzel81NUxM4UWTljt7NeOG6ji5PVC7feYiRH/1Osc3O6AEteeLKdi5trzI0fqgZ1E8iIiLiqGqTJJs1axYjRoxg6tSpxMbG8sYbb/DVV1+xfft2wsLOXNZx22230bdvX/r06YOfnx///ve/mTNnDn/++SeNGzeuUJsaPIlIbXKi0MrsdWm8t3w3aYeNhNfpO2KGB/mxIfUIK3ZlsmxnJpv2ll1C6W0x0aNZCBe3NhJjHRsFOX2WT05+0clZZ0byrGQWWtqRPJw9PznQz4vbezdjZN9owgL9nPvwC0B6dj7XTVlBRk4B/VqH8tFdPZ2yVLciZq/by2NfbQTgX0M6cXvvZm5pt6I0fqgZ1E8iIiLiqGqTJIuNjaVnz55MnjwZAJvNRlRUFA899BBPPvnkee+3Wq3Ur1+fyZMnM2LEiHKvKSgooKDg1CyFnJwcoqKiNHgSkVql2Grjx83pvLssic37cgCwmE34eZnJ/UsNsdZhdU9bQhlCgI+XJ0Imv8hKVm4hJwqLyS2wkldo5USRcXyi0EpeYTF5RVby/vLeGdcVFXOi0Mqx/GIKim2AMUPthouacN8lLWgeWscjn6+6ySss5uZ3E9i8L4fWYXX5+u993F4r7n+/7OS/v+zAbIJpI3pwWftwt7Z/Lkq+1AzqJxEREXGUq8YPDv0WVVhYyLp16xg3blzpObPZTHx8PAkJCRV6Rl5eHkVFRYSEhJz1mkmTJvH88887EpqIyAXHy2JmcEwj/tYlkpVJWUxdmsTynZnkFlppUMeHvq1C6dc6lH6tGxIRXD1mWPl5W2hcweWcFWGz2fllawZTlyaxPvUoX6xJZebvqVzZMYL7+7eka1Q9p7VV09hsdh6dlcjmfTmE1PHhgzt7emQzhX9c1op9R/P4cu1eHpyxgVn396ZLk3puj0NEREREpKocmkm2f/9+GjduzMqVK4mLiys9//jjj7N06VJWr1593mf8/e9/56effuLPP//Ez6/8X+o0k0xEpHy7Dx0nv8hGu4jAalko3ZV+33OYd5cm8cvWg6XnercI4YH+LenfpmGt2yzg5R+3MXVpEj4WMzPujaVH9Nn/8cnViqw27p7+O8t3ZhJa14c5f+9LVEiAx+IpoRlKNYP6SURERBxVLWaSVdXLL7/MzJkzWbJkyVkTZAC+vr74+vq6MTIRkZqhRcO6ng7BY3pGh9AzOoQdGcd4d+luvk3cx6rdh1m1+zDtIgJ5oH9L/tYl0m31uDzpy7VpTF2aBMC/b+zs0QQZgLfFzNu3XcTN765i64Ec7vpoDV+P7kO9gPI3mxARERERqY4c+k0iNDQUi8VCRkZGmfMZGRlERESc895XX32Vl19+mZ9//pkuXbo4HqmIiAjQJjyQ126OYdnjAxl1cXPq+FjYln6MR2Yl0v8/S/jot2TyCos9HabLrNqdxdNzNgHw0KWtuL5bEw9HZAj082b6yJ40CvYj6VAu932yjvwi6/lvFBERERGpJhxKkvn4+NC9e3cWLVpUes5ms7Fo0aIyyy//6pVXXuHFF19kwYIF9OjRo/LRioiInNSonj/P/K0DK5+8jP8b1JbQuj7sO3qC57/fQt+XF/PfhTs4nFvo6TCdKjkzlwc+W0eR1c41XSJ5NL6Np0MqIzzIj49G9iLQ14s1ew7z2FcbsdmcvN2piIiIiIiLOLy75axZs7jzzjt599136dWrF2+88QZffvkl27ZtIzw8nBEjRtC4cWMmTZoEwL///W/Gjx/PjBkz6Nu3b+lz6tatS926FVs2pFoVIiJyPvlFVr5ev5f3lu0mJSsPAD9vM8N6RDGqX4tK1cjKLSgmPSefjOx80nPy/3JcQEZ2Pg3q+nBXn2iu69oYHy/XLfXMzivi+rd/Y3dmLjFR9Zh1X2/8vC0ua68qVu7K5M6P1lBktXN//xaMu6q9R+LQ+KFmUD+JiIiIo1w1fnA4SQYwefJk/vOf/5Cenk7Xrl158803iY2NBWDAgAFER0czffp0AKKjo0lJSTnjGRMmTOC5556rUHsaPImISEVZbXYWbE5n6tIkNu3LBsBiNnFN50ju79+Cjo2CsdrsZB0vMJJd2flknEyApWcXlB5nZOdzrKDiyzYjg/245+Lm3NKrKXV9nVvys8hq484P17AyKYtGwX7MfbAvYYHVY0fTs5mzYS+PztoIwAvXdWREXLTbY9D4oWZQP4mIiIijqlWSzN00eBIREUfZ7XYSkrKYumw3y3YcKj0fFuhLVm4h1gouA6zr60V4kC8RwX6EB/kREeRXehwe5Meq3Vl8sCKZQ8eMXZmD/b0ZEdeMu/pE06Bu1TehsdvtPDVnE1+sSaOOj4XZo/vQPrJm/L9w8uKdvPrzDswmePeOHlzeIdyt7Wv8UDOon0RERMRRSpJp8CQiIpX05/5s3l26mx/+2E9JbsxsgoaBvkScTHaVlwSLCPar0Kyw/CIrczbs471lu0nOzAXA18vMsJ5R3FvJpZ4l3l++m3/N24rJBO+P6MFl7d2baKoKu93OuG82MfP3NPy8zcy6L46YqHpua1/jh5pB/SQiIiKOUpJMgycREami9JP1xCKC/Ait64OXxbk1xKw2Oz//mc47S5P4Y2/ZpZ4P9G9Jh0aO/T/sly0Z3PvpWux2eOaa9ozq18Kp8bpDsdXGPR+vZemOQ4TW9eGb0X1p2qDySUNHaPxQM6ifRERExFFKkmnwJCIiNUTJUs93liaxfGdm6fn+bRryQP+W9G4RgslkOucztuzP4capK8krtDI8tikvDel03nuqq+MFxQx7N4E/9+fQIrQOX4/uQ/06Pi5vV+OHmkH9JCIiIo5y1fjBddtwiYiI1FImk4k+rUL59J5YfnjoYv7WJRKzCZbuOMSt01Zx/dsrWbA5HdtZ6qIdzMnnno9/J6/QSt9WDXj+2o41NkEGRl23j+7qSeN6/uzOzOXeT9aSX2T1dFgiIiIiImUoSSYiIuJCnRoHM3n4Rfz62ABu790UHy8ziWlHeeCzdcT/dymzfk+loPhUwuhEoZV7P1nLgex8WjSsw9vDu+Pt5GWhnhAW5Mf0kT0J9PNibcoR/vnlxrMmCUVEREREPKHmj7pFRERqgGYN6vCvIZ357YlLGTOwJYF+Xuw+lMsTX2/ikld+5b1lSeTkF/HPrxLZuDeb+gHefHRXT4IDvD0dutO0Dg/kvTt64G0xMW/TASb9uNXTIYmIiIiIlFJNMhEREQ84ll/EF2tS+WBFMhk5BQD4eJkpLLbhbTHx2T2xxLZo4OEoXePbxH08PDMRgOcGd+Cuvs1d0o7GDzWD+klEREQcpZpkIiIiF5BAP2/uu6Qlyx4fyL9v6EyLhnUoLLYBMGlolws2QQZwXdfGPH5lWwCe/2ELS7Yf9HBEIiIiIiLg5ekAREREajNfLwvDejblpu5RLNlxEBMmBrYL83RYLje6f0v2HjlB8qFcujWt7+lwRERERESUJBMREakOzGYTl7YL93QYbmMymXjh2o7Y7MYyUxERERERT1OSTERERDzC6wLYtVNERERELhwanYqIiIiIiIiISK2nJJmIiIiIiIiIiNR6SpKJiIiIiIiIiEitpySZiIiIiIiIiIjUekqSiYiIiIiIiIhIrackmYiIiIiIiIiI1HpKkomIiIiIiIiISK2nJJmIiIiIlJoyZQrR0dH4+fkRGxvLmjVrznn9V199Rbt27fDz86Nz587Mnz/fTZGKiIiIOJeSZCIiIiICwKxZsxg7diwTJkxg/fr1xMTEMGjQIA4ePFju9StXruTWW2/lnnvuYcOGDQwZMoQhQ4awefNmN0cuIiIiUnUmu91u93QQ55OTk0NwcDDZ2dkEBQV5OhwRERGpATR+cFxsbCw9e/Zk8uTJANhsNqKionjooYd48sknz7h+2LBh5Obm8sMPP5Se6927N127dmXq1KkValP9JCIiIo5y1fjBy2lPcqGSPF5OTo6HIxEREZGaomTcUAP+PbBaKCwsZN26dYwbN670nNlsJj4+noSEhHLvSUhIYOzYsWXODRo0iLlz5561nYKCAgoKCkq/z87OBjTOExERkYpz1TivRiTJjh07BkBUVJSHIxEREZGa5tixYwQHB3s6jGovMzMTq9VKeHh4mfPh4eFs27at3HvS09PLvT49Pf2s7UyaNInnn3/+jPMa54mIiIijsrKynDrOqxFJskaNGpGWlkZgYCAmk8npz8/JySEqKoq0tDRN868G1B/Vi/qjelF/VC/qj+rlr/1ht9s5duwYjRo18nRocppx48aVmX129OhRmjVrRmpqqpKZ1ZT+rqsZ1E81g/qpZlA/VX/Z2dk0bdqUkJAQpz63RiTJzGYzTZo0cXk7QUFB+gGoRtQf1Yv6o3pRf1Qv6o/q5fT+UNKl4kJDQ7FYLGRkZJQ5n5GRQURERLn3REREOHQ9gK+vL76+vmecDw4O1s9RNae/62oG9VPNoH6qGdRP1Z/Z7Nz9KLW7pYiIiIjg4+ND9+7dWbRoUek5m83GokWLiIuLK/eeuLi4MtcDLFy48KzXi4iIiFRnNWImmYiIiIi43tixY7nzzjvp0aMHvXr14o033iA3N5eRI0cCMGLECBo3bsykSZMAePjhh+nfvz+vvfYa11xzDTNnzmTt2rW89957nvwYIiIiIpWiJBnGtP8JEyaUO/Vf3E/9Ub2oP6oX9Uf1ov6oXtQfVTds2DAOHTrE+PHjSU9Pp2vXrixYsKC0OH9qamqZZQ19+vRhxowZPPPMMzz11FO0bt2auXPn0qlTpwq3qX6r/tRHNYP6qWZQP9UM6qfqz1V9ZLJrX3QREREREREREanlVJNMRERERERERERqPSXJRERERERERESk1lOSTEREREREREREaj0lyUREREREREREpNar9UmyKVOmEB0djZ+fH7GxsaxZs8bTIdVazz33HCaTqcyrXbt2ng6r1li2bBmDBw+mUaNGmEwm5s6dW+Z9u93O+PHjiYyMxN/fn/j4eHbu3OmZYGuB8/XHXXfddcbPy5VXXumZYC9wkyZNomfPngQGBhIWFsaQIUPYvn17mWvy8/MZM2YMDRo0oG7dutxwww1kZGR4KOILW0X6Y8CAAWf8fDzwwAMeiljA8fHWV199Rbt27fDz86Nz587Mnz/fTZHWXo700bRp0+jXrx/169enfv36xMfHawztJpX93WXmzJmYTCaGDBni2gAFcLyfjh49ypgxY4iMjMTX15c2bdro7z0Xc7SP3njjDdq2bYu/vz9RUVE8+uij5Ofnuyna2ul8vw+VZ8mSJVx00UX4+vrSqlUrpk+f7nC7tTpJNmvWLMaOHcuECRNYv349MTExDBo0iIMHD3o6tFqrY8eOHDhwoPS1YsUKT4dUa+Tm5hITE8OUKVPKff+VV17hzTffZOrUqaxevZo6deowaNAg/c/BRc7XHwBXXnllmZ+XL774wo0R1h5Lly5lzJgxrFq1ioULF1JUVMQVV1xBbm5u6TWPPvoo33//PV999RVLly5l//79DB061INRX7gq0h8A9957b5mfj1deecVDEYuj462VK1dy6623cs8997BhwwaGDBnCkCFD2Lx5s5sjrz0c7aMlS5Zw66238uuvv5KQkEBUVBRXXHEF+/btc3PktUtlf3fZs2cPjz32GP369XNTpLWbo/1UWFjI5Zdfzp49e5g9ezbbt29n2rRpNG7c2M2R1x6O9tGMGTN48sknmTBhAlu3buWDDz5g1qxZPPXUU26OvHapyO9Dp0tOTuaaa65h4MCBJCYm8sgjjzBq1Ch++uknxxq212K9evWyjxkzpvR7q9Vqb9SokX3SpEkejKr2mjBhgj0mJsbTYYjdbgfsc+bMKf3eZrPZIyIi7P/5z39Kzx09etTu6+tr/+KLLzwQYe3y1/6w2+32O++8037dddd5JJ7a7uDBg3bAvnTpUrvdbvwseHt727/66qvSa7Zu3WoH7AkJCZ4Ks9b4a3/Y7XZ7//797Q8//LDngpIyHB1v3XzzzfZrrrmmzLnY2Fj7/fff79I4a7OqjomLi4vtgYGB9o8//thVIYq9cv1UXFxs79Onj/3999/X2MFNHO2nd955x96iRQt7YWGhu0Ks9RztozFjxtgvvfTSMufGjh1r79u3r0vjlFPK+33orx5//HF7x44dy5wbNmyYfdCgQQ61VWtnkhUWFrJu3Tri4+NLz5nNZuLj40lISPBgZLXbzp07adSoES1atOC2224jNTXV0yEJRlY+PT29zM9LcHAwsbGx+nnxoCVLlhAWFkbbtm0ZPXo0WVlZng6pVsjOzgYgJCQEgHXr1lFUVFTm56Ndu3Y0bdpUPx9u8Nf+KPH5558TGhpKp06dGDduHHl5eZ4Ir9arzHgrISGhzPUAgwYN0s+TizhjTJyXl0dRUdEZP4fiPJXtpxdeeIGwsDDuueced4RZ61Wmn7777jvi4uIYM2YM4eHhdOrUiYkTJ2K1Wt0Vdq1SmT7q06cP69atK12SuXv3bubPn8/VV1/tlpilYpw1fvByZlA1SWZmJlarlfDw8DLnw8PD2bZtm4eiqt1iY2OZPn06bdu25cCBAzz//PP069ePzZs3ExgY6OnwarX09HSAcn9eSt4T97ryyisZOnQozZs3JykpiaeeeoqrrrqKhIQELBaLp8O7YNlsNh555BH69u1Lp06dAOPnw8fHh3r16pW5Vj8frldefwAMHz6cZs2a0ahRI/744w+eeOIJtm/fzjfffOPBaGunyoy30tPT9f8bN3LGmPiJJ56gUaNGZ/xyIs5TmX5asWIFH3zwAYmJiW6IUKBy/bR7924WL17Mbbfdxvz589m1axd///vfKSoqYsKECe4Iu1apTB8NHz6czMxMLr74Yux2O8XFxTzwwANablnNnG38kJOTw4kTJ/D396/Qc2ptkkyqn6uuuqr0uEuXLsTGxtKsWTO+/PJL/euXyF/ccsstpcedO3emS5cutGzZkiVLlnDZZZd5MLIL25gxY9i8ebPqJVYTZ+uP++67r/S4c+fOREZGctlll5GUlETLli3dHabIBe3ll19m5syZLFmyBD8/P0+HIycdO3aMO+64g2nTphEaGurpcOQcbDYbYWFhvPfee1gsFrp3786+ffv4z3/+oyRZNbFkyRImTpzI22+/TWxsLLt27eLhhx/mxRdf5Nlnn/V0eOJktTZJFhoaisViOWP3sYyMDCIiIjwUlZyuXr16tGnThl27dnk6lFqv5GciIyODyMjI0vMZGRl07drVQ1HJ6Vq0aEFoaCi7du1SksxFHnzwQX744QeWLVtGkyZNSs9HRERQWFjI0aNHy8wm0/9PXOts/VGe2NhYAHbt2qUkmZtVZrwVERGh8ZkbVWVM/Oqrr/Lyyy/zyy+/0KVLF1eGWes52k9JSUns2bOHwYMHl56z2WwAeHl5sX37dv196AKV+XmKjIzE29u7zEqA9u3bk56eTmFhIT4+Pi6NubapTB89++yz3HHHHYwaNQow/gEuNzeX++67j6effhqzudZWsapWzjZ+CAoKqvAsMqjFu1v6+PjQvXt3Fi1aVHrOZrOxaNEi4uLiPBiZlDh+/DhJSUllkjLiGc2bNyciIqLMz0tOTg6rV6/Wz0s1sXfvXrKysvTz4gJ2u50HH3yQOXPmsHjxYpo3b17m/e7du+Pt7V3m52P79u2kpqbq58MFztcf5SlZaqSfD/erzHgrLi6uzPUACxcu1M+Ti1R2TPzKK6/w4osv8v/t3VlIVP0fx/HPlM7omE9plg3SZrZDRbSJUbTQBm0YGohoF4lZ0UVFEoVWBl6EXUR5ES0XRVFBCy0WbTdWVKAmZIYoFaRUFGFZUfh9LqLhP3+jMmzmac77BQdmzjkz8/3x5TBnPpz5nYqKCk2YMCEYpTpaZ/s0YsQI1dbWqrq62r8sWrTIf9e3/v37B7N8x/id4yktLU0NDQ3+EFOSHj9+LJ/PR0D2B/xOj9ra2joEYd9Cza9zyuO/oMvOHzo1zX+YOX78uHk8Hjt8+LA9fPjQ8vLyrFevXtbS0hLq0hxp/fr1dvPmTWtqarLKykqbPXu2JSQk2IsXL0JdmiO0trZaVVWVVVVVmSQrKyuzqqoqe/LkiZmZlZaWWq9evezs2bP24MEDW7x4sQ0ePNg+fPgQ4srD04/60draahs2bLDbt29bU1OTXb161caPH29Dhw61jx8/hrr0sLNq1Srr2bOn3bx505qbm/1LW1ubf5/8/HwbMGCAXb9+3e7fv2+pqamWmpoawqrD18/60dDQYNu3b7f79+9bU1OTnT171pKTk23atGkhrty5fna+lZ2dbYWFhf79KysrLSIiwnbt2mV1dXVWVFRkkZGRVltbG6ohhL3O9qi0tNTcbredOnUq4DhsbW0N1RAcobN9+n/c3TI4Otunp0+fWmxsrK1Zs8bq6+vt/Pnz1rdvXyspKQnVEMJeZ3tUVFRksbGxduzYMWtsbLQrV67YkCFDLCMjI1RDcISf/T4tLCy07Oxs//6NjY3m9Xpt48aNVldXZ3v37rXu3btbRUVFpz7X0SGZmdmePXtswIAB5na7bdKkSXbnzp1Ql+RYmZmZ5vP5zO12W1JSkmVmZlpDQ0Ooy3KMGzdumKQOS05OjpmZtbe329atWy0xMdE8Ho/NmjXL6uvrQ1t0GPtRP9ra2mzOnDnWp08fi4yMtIEDB9rKlSsJ+P+Q7/VBkh06dMi/z4cPH6ygoMDi4uLM6/Xa0qVLrbm5OXRFh7Gf9ePp06c2bdo0i4+PN4/HYykpKbZx40Z7+/ZtaAt3uB+db02fPt3/XfPNiRMnbNiwYeZ2u2306NF24cKFIFfsPJ3p0cCBA797HBYVFQW/cIfp7LH0vwjJgqezfbp165ZNnjzZPB6PJScn286dO+3Lly9BrtpZOtOjz58/W3FxsQ0ZMsSioqKsf//+VlBQYG/evAl+4Q7ys9+nOTk5Nn369A6vGTdunLndbktOTg44X/9VLjOuDwQAAAAAAICzOXZOMgAAAAAAAOAbQjIAAAAAAAA4HiEZAAAAAAAAHI+QDAAAAAAAAI5HSAYAAAAAAADHIyQDAAAAAACA4xGSAQAAAAAAwPEIyQAAAAAAAOB4hGQAAAAAgLDhcrl05syZUJcB4C9ESAYAAAAA6BK5ublyuVwdlnnz5oW6NAD4qYhQFwAAAAAACB/z5s3ToUOHAtZ5PJ4QVQMAv44ryQAAAAAAXcbj8ahfv34BS1xcnKSvf4UsLy/X/PnzFR0dreTkZJ06dSrg9bW1tZo5c6aio6PVu3dv5eXl6d27dwH7HDx4UKNHj5bH45HP59OaNWsCtr969UpLly6V1+vV0KFDde7cuT87aABhgZAMAAAAABA0W7duVXp6umpqapSVlaXly5errq5OkvT+/XvNnTtXcXFxunfvnk6ePKmrV68GhGDl5eVavXq18vLyVFtbq3PnziklJSXgM7Zt26aMjAw9ePBACxYsUFZWll6/fh3UcQL4+7jMzEJdBAAAAADg75ebm6sjR44oKioqYP3mzZu1efNmuVwu5efnq7y83L9typQpGj9+vPbt26f9+/dr06ZNevbsmWJiYiRJFy9e1MKFC/X8+XMlJiYqKSlJK1asUElJyXdrcLlc2rJli3bs2CHpa/DWo0cPXbp0ibnRAPwQc5IBAAAAALrMjBkzAkIwSYqPj/c/Tk1NDdiWmpqq6upqSVJdXZ3Gjh3rD8gkKS0tTe3t7aqvr5fL5dLz5881a9asH9YwZswY/+OYmBj9888/evHixe8OCYBDEJIBAAAAALpMTExMh78/dpXo6Ohf2i8yMjLgucvlUnt7+58oCUAYYU4yAAAAAEDQ3Llzp8PzkSNHSpJGjhypmpoavX//3r+9srJS3bp10/DhwxUbG6tBgwbp2rVrQa0ZgDNwJRkAAAAAoMt8+vRJLS0tAesiIiKUkJAgSTp58qQmTJigqVOn6ujRo7p7964OHDggScrKylJRUZFycnJUXFysly9fau3atcrOzlZiYqIkqbi4WPn5+erbt6/mz5+v1tZWVVZWau3atcEdKICwQ0gGAAAAAOgyFRUV8vl8AeuGDx+uR48eSfp658njx4+roKBAPp9Px44d06hRoyRJXq9Xly9f1rp16zRx4kR5vV6lp6errKzM/145OTn6+PGjdu/erQ0bNighIUHLli0L3gABhC3ubgkAAAAACAqXy6XTp09ryZIloS4FADpgTjIAAAAAAAA4HiEZAAAAAAAAHI85yQAAAAAAQcFsPwD+y7iSDAAAAAAAAI5HSAYAAAAAAADHIyQDAAAAAACA4xGSAQAAAAAAwPEIyQAAAAAAAOB4hGQAAAAAAABwPEIyAAAAAAAAOB4hGQAAAAAAABzvX0UvJTRuzlexAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "encoding": "# coding: utf-8",
      "executable": "/usr/bin/env python",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}